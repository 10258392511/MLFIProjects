{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0864f6f8-d36b-4bb2-9a39-ce2e9780c5f4",
   "metadata": {},
   "source": [
    "# Coding Project 1 : Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5b0c7d-92b3-4cde-a31b-93ff1e7ff46f",
   "metadata": {},
   "source": [
    "**Please write the names of all group members here:**\n",
    "Zhexin Wu,\n",
    "Fangyuan Sun,\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "*Note:* The provided structure for the code below is only suggestive, and if you want to structure your programs differently you may do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eba37405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install seaborn optuna optuna-integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee5098cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs\n",
    "SEED = 10\n",
    "TGT_NAME = \"SalePrice\"\n",
    "TEST_SPLIT = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee87ace5-781a-402a-8f0b-3266c446cd30",
   "metadata": {},
   "source": [
    "### Question 1 - Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26013cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Question 1, you can import the following packages:\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import optuna\n",
    "import optuna.distributions as opt_distr\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, FunctionTransformer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.pipeline import Pipeline\n",
    "from optuna_integration import OptunaSearchCV\n",
    "from collections import defaultdict\n",
    "from typing import List, Callable, Iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13602b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For better visualization\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4c976ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GdPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>2500</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>266500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>142125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>147500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows Ã— 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "Id                                                                      \n",
       "1             60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "2             20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "3             60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "4             70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "5             60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "...          ...      ...          ...      ...    ...   ...      ...   \n",
       "1456          60       RL         62.0     7917   Pave   NaN      Reg   \n",
       "1457          20       RL         85.0    13175   Pave   NaN      Reg   \n",
       "1458          70       RL         66.0     9042   Pave   NaN      Reg   \n",
       "1459          20       RL         68.0     9717   Pave   NaN      Reg   \n",
       "1460          20       RL         75.0     9937   Pave   NaN      Reg   \n",
       "\n",
       "     LandContour Utilities LotConfig  ... PoolArea PoolQC  Fence MiscFeature  \\\n",
       "Id                                    ...                                      \n",
       "1            Lvl    AllPub    Inside  ...        0    NaN    NaN         NaN   \n",
       "2            Lvl    AllPub       FR2  ...        0    NaN    NaN         NaN   \n",
       "3            Lvl    AllPub    Inside  ...        0    NaN    NaN         NaN   \n",
       "4            Lvl    AllPub    Corner  ...        0    NaN    NaN         NaN   \n",
       "5            Lvl    AllPub       FR2  ...        0    NaN    NaN         NaN   \n",
       "...          ...       ...       ...  ...      ...    ...    ...         ...   \n",
       "1456         Lvl    AllPub    Inside  ...        0    NaN    NaN         NaN   \n",
       "1457         Lvl    AllPub    Inside  ...        0    NaN  MnPrv         NaN   \n",
       "1458         Lvl    AllPub    Inside  ...        0    NaN  GdPrv        Shed   \n",
       "1459         Lvl    AllPub    Inside  ...        0    NaN    NaN         NaN   \n",
       "1460         Lvl    AllPub    Inside  ...        0    NaN    NaN         NaN   \n",
       "\n",
       "     MiscVal MoSold  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "Id                                                               \n",
       "1          0      2    2008        WD         Normal     208500  \n",
       "2          0      5    2007        WD         Normal     181500  \n",
       "3          0      9    2008        WD         Normal     223500  \n",
       "4          0      2    2006        WD        Abnorml     140000  \n",
       "5          0     12    2008        WD         Normal     250000  \n",
       "...      ...    ...     ...       ...            ...        ...  \n",
       "1456       0      8    2007        WD         Normal     175000  \n",
       "1457       0      2    2010        WD         Normal     210000  \n",
       "1458    2500      5    2010        WD         Normal     266500  \n",
       "1459       0      4    2010        WD         Normal     142125  \n",
       "1460       0      6    2008        WD         Normal     147500  \n",
       "\n",
       "[1460 rows x 80 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1.a) Import the dataset Housing.csv into Python as a pandas DataFrame and call it Housing.\n",
    "#To determine whether a variable is categorical or numerical, please refer to the file description.txt.\n",
    "#Remember that the first column of the csv file is an index column and should not be considered as an explanatory variable.\n",
    "data_df = pd.read_csv(\"data/Housing.csv\", index_col=\"Id\")\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ac46810",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Visualization of Missing Values, Indicated by the Bright Color')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1296x691.2 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check NA\n",
    "is_na = data_df.isna()\n",
    "fig, axis = plt.subplots(figsize=(18, 9.6))\n",
    "sns.heatmap(is_na, ax=axis)\n",
    "axis.set_title(\n",
    "    \"Visualization of Missing Values, Indicated by the Bright Color\",\n",
    "    fontdict={\n",
    "        \"fontsize\": 20\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f0d913d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_name</th>\n",
       "      <th>dtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LotArea</td>\n",
       "      <td>numerical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Street</td>\n",
       "      <td>categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alley</td>\n",
       "      <td>categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LotShape</td>\n",
       "      <td>categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LandContour</td>\n",
       "      <td>categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>PoolQC</td>\n",
       "      <td>categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Fence</td>\n",
       "      <td>categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>MiscFeature</td>\n",
       "      <td>categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>SaleType</td>\n",
       "      <td>categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>SaleCondition</td>\n",
       "      <td>categorical</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        feat_name        dtype\n",
       "0         LotArea    numerical\n",
       "1          Street  categorical\n",
       "2           Alley  categorical\n",
       "3        LotShape  categorical\n",
       "4     LandContour  categorical\n",
       "..            ...          ...\n",
       "59         PoolQC  categorical\n",
       "60          Fence  categorical\n",
       "61    MiscFeature  categorical\n",
       "62       SaleType  categorical\n",
       "63  SaleCondition  categorical\n",
       "\n",
       "[64 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Read dtype from data_description.txt to ensure consistency with data_df.dtypes\n",
    "\"\"\"\n",
    "with open(\"data/data_description.txt\", \"r\") as rf:\n",
    "    data_desc = rf.read()\n",
    "desc_out = re.findall(r\"(\\w+) *\\((\\w+)\\):[\\w ]+\\n\", data_desc)\n",
    "desc_out_df = pd.DataFrame(desc_out, columns=[\"feat_name\", \"dtype\"])\n",
    "desc_out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c9d4851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of categorical features:\n",
      "From data_df: 43\n",
      "From desc: 38\n",
      "Differences: ['Functional', 'MSZoning', 'Exterior2nd', 'Condition2', 'BsmtFinType2']\n"
     ]
    }
   ],
   "source": [
    "data_df_categorical_feats = data_df.dtypes[data_df.dtypes == \"object\"].index.values\n",
    "data_desc_categorical_feats = desc_out_df.loc[desc_out_df[\"dtype\"] == \"categorical\", \"feat_name\"]\n",
    "# np.all(data_df_categorical_feats == data_desc_categorical_feats)\n",
    "print(f\"Number of categorical features:\\nFrom data_df: {data_df_categorical_feats.shape[0]}\\nFrom desc: {data_desc_categorical_feats.shape[0]}\")\n",
    "diff_feat_names = set(data_df_categorical_feats).difference(set(data_desc_categorical_feats))\n",
    "diff_feat_names = list(diff_feat_names)\n",
    "print(f\"Differences: {diff_feat_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcc4608c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Functional</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>Exterior2nd</th>\n",
       "      <th>Condition2</th>\n",
       "      <th>BsmtFinType2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Typ</td>\n",
       "      <td>RL</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Unf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Typ</td>\n",
       "      <td>RL</td>\n",
       "      <td>MetalSd</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Unf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Typ</td>\n",
       "      <td>RL</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Unf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Typ</td>\n",
       "      <td>RL</td>\n",
       "      <td>Wd Shng</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Unf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Typ</td>\n",
       "      <td>RL</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Unf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>Typ</td>\n",
       "      <td>RL</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Unf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>Min1</td>\n",
       "      <td>RL</td>\n",
       "      <td>Plywood</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Rec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>Typ</td>\n",
       "      <td>RL</td>\n",
       "      <td>CmentBd</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Unf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>Typ</td>\n",
       "      <td>RL</td>\n",
       "      <td>MetalSd</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Rec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>Typ</td>\n",
       "      <td>RL</td>\n",
       "      <td>HdBoard</td>\n",
       "      <td>Norm</td>\n",
       "      <td>LwQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Functional MSZoning Exterior2nd Condition2 BsmtFinType2\n",
       "Id                                                          \n",
       "1           Typ       RL     VinylSd       Norm          Unf\n",
       "2           Typ       RL     MetalSd       Norm          Unf\n",
       "3           Typ       RL     VinylSd       Norm          Unf\n",
       "4           Typ       RL     Wd Shng       Norm          Unf\n",
       "5           Typ       RL     VinylSd       Norm          Unf\n",
       "...         ...      ...         ...        ...          ...\n",
       "1456        Typ       RL     VinylSd       Norm          Unf\n",
       "1457       Min1       RL     Plywood       Norm          Rec\n",
       "1458        Typ       RL     CmentBd       Norm          Unf\n",
       "1459        Typ       RL     MetalSd       Norm          Rec\n",
       "1460        Typ       RL     HdBoard       Norm          LwQ\n",
       "\n",
       "[1460 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df[diff_feat_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022d36a9",
   "metadata": {},
   "source": [
    "<span style=\"color: blue;\"><strong>Conclusion:</strong></span>\n",
    "1. The 5 features not included in data_description.txt are also categorical, so we can rely on `data_df.dtypes == \"object\"` for selecting categorical features.\n",
    "1. Note that we have substantial NA's in the dataset, but according to data_description.txt, they don't mean missing values but count as one category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c485f3b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: ylabel='Frequency'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#1.b) Determine graphically whether the target variable SalePrice exhibits a Gaussian distribution.\n",
    "data_df[TGT_NAME].plot(kind=\"hist\", bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39025979",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.probplot(data_df[TGT_NAME], dist='norm', plot=plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7325053f",
   "metadata": {},
   "source": [
    "<span style=\"color: blue;\"><strong>Conclusion:</strong></span>\n",
    "From the histogram we see that *SalePrice* is positively skewed, and the Q-Q plot also implies that the distribution does not seem to be Gaussian (right-skewed). Therefore, we use a log transform on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11892029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#If not, suggest a suitable transformation to bring SalePrice close to a Gaussian distribution (logarithmic, inverse, square-root, ...).\n",
    "np.log(data_df[TGT_NAME]).plot(kind=\"hist\", bins=100)\n",
    "#Do not forget to apply this transformation to the target variable SalePrice in the dataset and perform the regressions of Q2-Q3 on this transformed target.\n",
    "data_tgt_tfm_df = data_df.copy()\n",
    "data_tgt_tfm_df[TGT_NAME] = np.log(data_tgt_tfm_df[TGT_NAME])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e11e588",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.probplot(data_tgt_tfm_df[TGT_NAME], dist='norm', plot=plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14daaec7",
   "metadata": {},
   "source": [
    "<span style=\"color: blue;\"><strong>Conclusion:</strong></span>\n",
    "After log transformation, we see that $log(\\text{Saleprice})$ is approximately Gaussian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e3a953a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1460, 79), (1460,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_all = data_tgt_tfm_df.pop(TGT_NAME)\n",
    "X_all = data_tgt_tfm_df.copy()\n",
    "X_all.shape, y_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb70d1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.c) Replace missing values with the mean (resp. mode) of their respective columns for numerical variables (resp. categorical) using pd.fillna(...).\n",
    "#Pay attention that some categorical variables admit 'NA' as a category, which is therefore not a missing value in this case.\n",
    "\n",
    "#Use one-hot encoding for the categorical features using the default function pd.get_dummies(...). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efd4eee",
   "metadata": {},
   "source": [
    "<span style=\"color: blue;\"><strong>Notes:</strong></span>\n",
    "- For convenience for model training, we instead decide to use `ColumnTransformer` for better integration\n",
    "- Note that the transforms should be performed at runtime using statistics of the training set, especially when doing cross validation where each fit relies on different training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c4fde21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1460x304 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 97976 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_tfm = Pipeline(\n",
    "    [\n",
    "        (\"na_imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"NA\")),\n",
    "        (\"one_hot_encoder\", OneHotEncoder(handle_unknown=\"ignore\")),  # Handling unknown categories during test time\n",
    "    ]\n",
    ")\n",
    "col_tfm = ColumnTransformer(\n",
    "    [\n",
    "        (\"numerical_imputer\", SimpleImputer(strategy=\"mean\"), make_column_selector(dtype_exclude=[\"object\", \"category\"])),\n",
    "        (\"categorical_tfm\", categorical_tfm, make_column_selector(dtype_include=[\"object\", \"category\"])), \n",
    "    ]\n",
    ")\n",
    "\n",
    "X_all_tfm = col_tfm.fit_transform(X_all)\n",
    "X_all_tfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c248239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numerical_imputer__MSSubClass</th>\n",
       "      <th>numerical_imputer__LotFrontage</th>\n",
       "      <th>numerical_imputer__LotArea</th>\n",
       "      <th>numerical_imputer__OverallQual</th>\n",
       "      <th>numerical_imputer__OverallCond</th>\n",
       "      <th>numerical_imputer__YearBuilt</th>\n",
       "      <th>numerical_imputer__YearRemodAdd</th>\n",
       "      <th>numerical_imputer__MasVnrArea</th>\n",
       "      <th>numerical_imputer__BsmtFinSF1</th>\n",
       "      <th>numerical_imputer__BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>categorical_tfm__SaleType_ConLw</th>\n",
       "      <th>categorical_tfm__SaleType_New</th>\n",
       "      <th>categorical_tfm__SaleType_Oth</th>\n",
       "      <th>categorical_tfm__SaleType_WD</th>\n",
       "      <th>categorical_tfm__SaleCondition_Abnorml</th>\n",
       "      <th>categorical_tfm__SaleCondition_AdjLand</th>\n",
       "      <th>categorical_tfm__SaleCondition_Alloca</th>\n",
       "      <th>categorical_tfm__SaleCondition_Family</th>\n",
       "      <th>categorical_tfm__SaleCondition_Normal</th>\n",
       "      <th>categorical_tfm__SaleCondition_Partial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>706.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1915.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>655.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>60.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>20.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1978.0</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>790.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>70.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1941.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>20.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1029.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>20.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1965.0</td>\n",
       "      <td>1965.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>830.0</td>\n",
       "      <td>290.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows Ã— 304 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      numerical_imputer__MSSubClass  numerical_imputer__LotFrontage  \\\n",
       "0                              60.0                            65.0   \n",
       "1                              20.0                            80.0   \n",
       "2                              60.0                            68.0   \n",
       "3                              70.0                            60.0   \n",
       "4                              60.0                            84.0   \n",
       "...                             ...                             ...   \n",
       "1455                           60.0                            62.0   \n",
       "1456                           20.0                            85.0   \n",
       "1457                           70.0                            66.0   \n",
       "1458                           20.0                            68.0   \n",
       "1459                           20.0                            75.0   \n",
       "\n",
       "      numerical_imputer__LotArea  numerical_imputer__OverallQual  \\\n",
       "0                         8450.0                             7.0   \n",
       "1                         9600.0                             6.0   \n",
       "2                        11250.0                             7.0   \n",
       "3                         9550.0                             7.0   \n",
       "4                        14260.0                             8.0   \n",
       "...                          ...                             ...   \n",
       "1455                      7917.0                             6.0   \n",
       "1456                     13175.0                             6.0   \n",
       "1457                      9042.0                             7.0   \n",
       "1458                      9717.0                             5.0   \n",
       "1459                      9937.0                             5.0   \n",
       "\n",
       "      numerical_imputer__OverallCond  numerical_imputer__YearBuilt  \\\n",
       "0                                5.0                        2003.0   \n",
       "1                                8.0                        1976.0   \n",
       "2                                5.0                        2001.0   \n",
       "3                                5.0                        1915.0   \n",
       "4                                5.0                        2000.0   \n",
       "...                              ...                           ...   \n",
       "1455                             5.0                        1999.0   \n",
       "1456                             6.0                        1978.0   \n",
       "1457                             9.0                        1941.0   \n",
       "1458                             6.0                        1950.0   \n",
       "1459                             6.0                        1965.0   \n",
       "\n",
       "      numerical_imputer__YearRemodAdd  numerical_imputer__MasVnrArea  \\\n",
       "0                              2003.0                          196.0   \n",
       "1                              1976.0                            0.0   \n",
       "2                              2002.0                          162.0   \n",
       "3                              1970.0                            0.0   \n",
       "4                              2000.0                          350.0   \n",
       "...                               ...                            ...   \n",
       "1455                           2000.0                            0.0   \n",
       "1456                           1988.0                          119.0   \n",
       "1457                           2006.0                            0.0   \n",
       "1458                           1996.0                            0.0   \n",
       "1459                           1965.0                            0.0   \n",
       "\n",
       "      numerical_imputer__BsmtFinSF1  numerical_imputer__BsmtFinSF2  ...  \\\n",
       "0                             706.0                            0.0  ...   \n",
       "1                             978.0                            0.0  ...   \n",
       "2                             486.0                            0.0  ...   \n",
       "3                             216.0                            0.0  ...   \n",
       "4                             655.0                            0.0  ...   \n",
       "...                             ...                            ...  ...   \n",
       "1455                            0.0                            0.0  ...   \n",
       "1456                          790.0                          163.0  ...   \n",
       "1457                          275.0                            0.0  ...   \n",
       "1458                           49.0                         1029.0  ...   \n",
       "1459                          830.0                          290.0  ...   \n",
       "\n",
       "      categorical_tfm__SaleType_ConLw  categorical_tfm__SaleType_New  \\\n",
       "0                                 0.0                            0.0   \n",
       "1                                 0.0                            0.0   \n",
       "2                                 0.0                            0.0   \n",
       "3                                 0.0                            0.0   \n",
       "4                                 0.0                            0.0   \n",
       "...                               ...                            ...   \n",
       "1455                              0.0                            0.0   \n",
       "1456                              0.0                            0.0   \n",
       "1457                              0.0                            0.0   \n",
       "1458                              0.0                            0.0   \n",
       "1459                              0.0                            0.0   \n",
       "\n",
       "      categorical_tfm__SaleType_Oth  categorical_tfm__SaleType_WD  \\\n",
       "0                               0.0                           1.0   \n",
       "1                               0.0                           1.0   \n",
       "2                               0.0                           1.0   \n",
       "3                               0.0                           1.0   \n",
       "4                               0.0                           1.0   \n",
       "...                             ...                           ...   \n",
       "1455                            0.0                           1.0   \n",
       "1456                            0.0                           1.0   \n",
       "1457                            0.0                           1.0   \n",
       "1458                            0.0                           1.0   \n",
       "1459                            0.0                           1.0   \n",
       "\n",
       "      categorical_tfm__SaleCondition_Abnorml  \\\n",
       "0                                        0.0   \n",
       "1                                        0.0   \n",
       "2                                        0.0   \n",
       "3                                        1.0   \n",
       "4                                        0.0   \n",
       "...                                      ...   \n",
       "1455                                     0.0   \n",
       "1456                                     0.0   \n",
       "1457                                     0.0   \n",
       "1458                                     0.0   \n",
       "1459                                     0.0   \n",
       "\n",
       "      categorical_tfm__SaleCondition_AdjLand  \\\n",
       "0                                        0.0   \n",
       "1                                        0.0   \n",
       "2                                        0.0   \n",
       "3                                        0.0   \n",
       "4                                        0.0   \n",
       "...                                      ...   \n",
       "1455                                     0.0   \n",
       "1456                                     0.0   \n",
       "1457                                     0.0   \n",
       "1458                                     0.0   \n",
       "1459                                     0.0   \n",
       "\n",
       "      categorical_tfm__SaleCondition_Alloca  \\\n",
       "0                                       0.0   \n",
       "1                                       0.0   \n",
       "2                                       0.0   \n",
       "3                                       0.0   \n",
       "4                                       0.0   \n",
       "...                                     ...   \n",
       "1455                                    0.0   \n",
       "1456                                    0.0   \n",
       "1457                                    0.0   \n",
       "1458                                    0.0   \n",
       "1459                                    0.0   \n",
       "\n",
       "      categorical_tfm__SaleCondition_Family  \\\n",
       "0                                       0.0   \n",
       "1                                       0.0   \n",
       "2                                       0.0   \n",
       "3                                       0.0   \n",
       "4                                       0.0   \n",
       "...                                     ...   \n",
       "1455                                    0.0   \n",
       "1456                                    0.0   \n",
       "1457                                    0.0   \n",
       "1458                                    0.0   \n",
       "1459                                    0.0   \n",
       "\n",
       "      categorical_tfm__SaleCondition_Normal  \\\n",
       "0                                       1.0   \n",
       "1                                       1.0   \n",
       "2                                       1.0   \n",
       "3                                       0.0   \n",
       "4                                       1.0   \n",
       "...                                     ...   \n",
       "1455                                    1.0   \n",
       "1456                                    1.0   \n",
       "1457                                    1.0   \n",
       "1458                                    1.0   \n",
       "1459                                    1.0   \n",
       "\n",
       "      categorical_tfm__SaleCondition_Partial  \n",
       "0                                        0.0  \n",
       "1                                        0.0  \n",
       "2                                        0.0  \n",
       "3                                        0.0  \n",
       "4                                        0.0  \n",
       "...                                      ...  \n",
       "1455                                     0.0  \n",
       "1456                                     0.0  \n",
       "1457                                     0.0  \n",
       "1458                                     0.0  \n",
       "1459                                     0.0  \n",
       "\n",
       "[1460 rows x 304 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For inspection\n",
    "X_all_tfm_df = pd.DataFrame(X_all_tfm.toarray(), columns=col_tfm.get_feature_names_out())\n",
    "X_all_tfm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e7fa4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['categorical_tfm__Alley_NA', 'categorical_tfm__Neighborhood_NAmes',\n",
      "       'categorical_tfm__MasVnrType_NA', 'categorical_tfm__BsmtQual_NA',\n",
      "       'categorical_tfm__BsmtCond_NA', 'categorical_tfm__BsmtExposure_NA',\n",
      "       'categorical_tfm__BsmtFinType1_NA', 'categorical_tfm__BsmtFinType2_NA',\n",
      "       'categorical_tfm__Electrical_NA', 'categorical_tfm__FireplaceQu_NA',\n",
      "       'categorical_tfm__GarageType_NA', 'categorical_tfm__GarageFinish_NA',\n",
      "       'categorical_tfm__GarageQual_NA', 'categorical_tfm__GarageCond_NA',\n",
      "       'categorical_tfm__PoolQC_NA', 'categorical_tfm__Fence_NA',\n",
      "       'categorical_tfm__MiscFeature_NA'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Check:\n",
    "- NA's are handled as a category\n",
    "- There are no missing values now\n",
    "\"\"\"\n",
    "print(X_all_tfm_df.columns[X_all_tfm_df.columns.str.contains(\"NA\")])\n",
    "X_all_tfm_df.isna().values.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf5dd6ed-bdad-4351-a2ff-01aded150b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>196.0</td>\n",
       "      <td>706</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>548</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>460</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>162.0</td>\n",
       "      <td>486</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>608</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>642</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>350.0</td>\n",
       "      <td>655</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>836</td>\n",
       "      <td>192</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>60</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1999</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>460</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>20</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1978</td>\n",
       "      <td>1988</td>\n",
       "      <td>119.0</td>\n",
       "      <td>790</td>\n",
       "      <td>163</td>\n",
       "      <td>...</td>\n",
       "      <td>500</td>\n",
       "      <td>349</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>70</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>1941</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>275</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>252</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2500</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>20</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1950</td>\n",
       "      <td>1996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49</td>\n",
       "      <td>1029</td>\n",
       "      <td>...</td>\n",
       "      <td>240</td>\n",
       "      <td>366</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>20</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1965</td>\n",
       "      <td>1965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>830</td>\n",
       "      <td>290</td>\n",
       "      <td>...</td>\n",
       "      <td>276</td>\n",
       "      <td>736</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "Id                                                                            \n",
       "1             60         65.0     8450            7            5       2003   \n",
       "2             20         80.0     9600            6            8       1976   \n",
       "3             60         68.0    11250            7            5       2001   \n",
       "4             70         60.0     9550            7            5       1915   \n",
       "5             60         84.0    14260            8            5       2000   \n",
       "...          ...          ...      ...          ...          ...        ...   \n",
       "1456          60         62.0     7917            6            5       1999   \n",
       "1457          20         85.0    13175            6            6       1978   \n",
       "1458          70         66.0     9042            7            9       1941   \n",
       "1459          20         68.0     9717            5            6       1950   \n",
       "1460          20         75.0     9937            5            6       1965   \n",
       "\n",
       "      YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  GarageArea  \\\n",
       "Id                                                      ...               \n",
       "1             2003       196.0         706           0  ...         548   \n",
       "2             1976         0.0         978           0  ...         460   \n",
       "3             2002       162.0         486           0  ...         608   \n",
       "4             1970         0.0         216           0  ...         642   \n",
       "5             2000       350.0         655           0  ...         836   \n",
       "...            ...         ...         ...         ...  ...         ...   \n",
       "1456          2000         0.0           0           0  ...         460   \n",
       "1457          1988       119.0         790         163  ...         500   \n",
       "1458          2006         0.0         275           0  ...         252   \n",
       "1459          1996         0.0          49        1029  ...         240   \n",
       "1460          1965         0.0         830         290  ...         276   \n",
       "\n",
       "      WoodDeckSF  OpenPorchSF  EnclosedPorch  3SsnPorch  ScreenPorch  \\\n",
       "Id                                                                     \n",
       "1              0           61              0          0            0   \n",
       "2            298            0              0          0            0   \n",
       "3              0           42              0          0            0   \n",
       "4              0           35            272          0            0   \n",
       "5            192           84              0          0            0   \n",
       "...          ...          ...            ...        ...          ...   \n",
       "1456           0           40              0          0            0   \n",
       "1457         349            0              0          0            0   \n",
       "1458           0           60              0          0            0   \n",
       "1459         366            0            112          0            0   \n",
       "1460         736           68              0          0            0   \n",
       "\n",
       "      PoolArea  MiscVal  MoSold  YrSold  \n",
       "Id                                       \n",
       "1            0        0       2    2008  \n",
       "2            0        0       5    2007  \n",
       "3            0        0       9    2008  \n",
       "4            0        0       2    2006  \n",
       "5            0        0      12    2008  \n",
       "...        ...      ...     ...     ...  \n",
       "1456         0        0       8    2007  \n",
       "1457         0        0       2    2010  \n",
       "1458         0     2500       5    2010  \n",
       "1459         0        0       4    2010  \n",
       "1460         0        0       6    2008  \n",
       "\n",
       "[1460 rows x 36 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1.d) Create a second pandas DataFrame from Housing without the categorical variables.\n",
    "# For that, use the function df.select_dtypes and exclude the variables with type 'object' and 'category'. Call this dataset Housing2.\n",
    "X_all_numerical = X_all.select_dtypes(exclude=[\"object\", \"category\"])\n",
    "X_all_numerical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86354e30-0b82-481b-a39f-c611e08a4408",
   "metadata": {},
   "source": [
    "### Question 2 - Linear Regression on Housing2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f00b8ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection  import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90946778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1022, 36), (1022,), (438, 36), (438,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2.a) Split the Housing2 data into a training set (X,Y)_train and a test set (X, Y)_test. \n",
    "#Randomly assign 70% of the observations to the training set and the remaining 30% to the test set.\n",
    "X_train_numerical, X_test_numerical, y_train, y_test = train_test_split(\n",
    "    X_all_numerical, \n",
    "    y_all, \n",
    "    test_size=TEST_SPLIT, \n",
    "    random_state=SEED, \n",
    "    shuffle=True\n",
    ")\n",
    "X_train_numerical.shape, y_train.shape, X_test_numerical.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e45a1994",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline(model: BaseEstimator):\n",
    "    categorical_tfm = Pipeline(\n",
    "        [\n",
    "            (\"na_imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"NA\")),\n",
    "            (\"one_hot_encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "        ]\n",
    "    )\n",
    "    col_tfm = ColumnTransformer(\n",
    "        [\n",
    "            (\"numerical_imputer\", SimpleImputer(strategy=\"mean\"), make_column_selector(dtype_exclude=[\"object\", \"category\"])),\n",
    "            (\"categorical_tfm\", categorical_tfm, make_column_selector(dtype_include=[\"object\", \"category\"])), \n",
    "        ]\n",
    "    )\n",
    "    pipeline = Pipeline(\n",
    "        [\n",
    "            (\"preprocessor\", col_tfm),\n",
    "            (\"model\", model)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b401471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;numerical_imputer&#x27;,\n",
       "                                                  SimpleImputer(),\n",
       "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001514688DEB0&gt;),\n",
       "                                                 (&#x27;categorical_tfm&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;na_imputer&#x27;,\n",
       "                                                                   SimpleImputer(fill_value=&#x27;NA&#x27;,\n",
       "                                                                                 strategy=&#x27;constant&#x27;)),\n",
       "                                                                  (&#x27;one_hot_encoder&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001514650A310&gt;)])),\n",
       "                (&#x27;model&#x27;, LinearRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;numerical_imputer&#x27;,\n",
       "                                                  SimpleImputer(),\n",
       "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001514688DEB0&gt;),\n",
       "                                                 (&#x27;categorical_tfm&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;na_imputer&#x27;,\n",
       "                                                                   SimpleImputer(fill_value=&#x27;NA&#x27;,\n",
       "                                                                                 strategy=&#x27;constant&#x27;)),\n",
       "                                                                  (&#x27;one_hot_encoder&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001514650A310&gt;)])),\n",
       "                (&#x27;model&#x27;, LinearRegression())])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;preprocessor: ColumnTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for preprocessor: ColumnTransformer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(transformers=[(&#x27;numerical_imputer&#x27;, SimpleImputer(),\n",
       "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001514688DEB0&gt;),\n",
       "                                (&#x27;categorical_tfm&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;na_imputer&#x27;,\n",
       "                                                  SimpleImputer(fill_value=&#x27;NA&#x27;,\n",
       "                                                                strategy=&#x27;constant&#x27;)),\n",
       "                                                 (&#x27;one_hot_encoder&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001514650A310&gt;)])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">numerical_imputer</label><div class=\"sk-toggleable__content fitted\"><pre>&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001514688DEB0&gt;</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;SimpleImputer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.impute.SimpleImputer.html\">?<span>Documentation for SimpleImputer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>SimpleImputer()</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">categorical_tfm</label><div class=\"sk-toggleable__content fitted\"><pre>&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001514650A310&gt;</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;SimpleImputer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.impute.SimpleImputer.html\">?<span>Documentation for SimpleImputer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>SimpleImputer(fill_value=&#x27;NA&#x27;, strategy=&#x27;constant&#x27;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;OneHotEncoder<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div> </div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LinearRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression()</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('numerical_imputer',\n",
       "                                                  SimpleImputer(),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x000001514688DEB0>),\n",
       "                                                 ('categorical_tfm',\n",
       "                                                  Pipeline(steps=[('na_imputer',\n",
       "                                                                   SimpleImputer(fill_value='NA',\n",
       "                                                                                 strategy='constant')),\n",
       "                                                                  ('one_hot_encoder',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x000001514650A310>)])),\n",
       "                ('model', LinearRegression())])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2.b) Fit a linear regression model on the training dataset (X, Y)_train using the sklearn package.\n",
    "#Output a table with the name of each feature and the associated regression coefficient. \n",
    "lr_pipeline = create_pipeline(LinearRegression())\n",
    "lr_pipeline.fit(X_train_numerical, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce3e315e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('preprocessor',\n",
       "  ColumnTransformer(transformers=[('numerical_imputer', SimpleImputer(),\n",
       "                                   <sklearn.compose._column_transformer.make_column_selector object at 0x000001514688DEB0>),\n",
       "                                  ('categorical_tfm',\n",
       "                                   Pipeline(steps=[('na_imputer',\n",
       "                                                    SimpleImputer(fill_value='NA',\n",
       "                                                                  strategy='constant')),\n",
       "                                                   ('one_hot_encoder',\n",
       "                                                    OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                   <sklearn.compose._column_transformer.make_column_selector object at 0x000001514650A310>)])),\n",
       " ('model', LinearRegression())]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_pipeline.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c258585d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['numerical_imputer__MSSubClass', 'numerical_imputer__LotFrontage',\n",
       "       'numerical_imputer__LotArea', 'numerical_imputer__OverallQual',\n",
       "       'numerical_imputer__OverallCond', 'numerical_imputer__YearBuilt',\n",
       "       'numerical_imputer__YearRemodAdd', 'numerical_imputer__MasVnrArea',\n",
       "       'numerical_imputer__BsmtFinSF1', 'numerical_imputer__BsmtFinSF2',\n",
       "       'numerical_imputer__BsmtUnfSF', 'numerical_imputer__TotalBsmtSF',\n",
       "       'numerical_imputer__1stFlrSF', 'numerical_imputer__2ndFlrSF',\n",
       "       'numerical_imputer__LowQualFinSF', 'numerical_imputer__GrLivArea',\n",
       "       'numerical_imputer__BsmtFullBath',\n",
       "       'numerical_imputer__BsmtHalfBath', 'numerical_imputer__FullBath',\n",
       "       'numerical_imputer__HalfBath', 'numerical_imputer__BedroomAbvGr',\n",
       "       'numerical_imputer__KitchenAbvGr',\n",
       "       'numerical_imputer__TotRmsAbvGrd', 'numerical_imputer__Fireplaces',\n",
       "       'numerical_imputer__GarageYrBlt', 'numerical_imputer__GarageCars',\n",
       "       'numerical_imputer__GarageArea', 'numerical_imputer__WoodDeckSF',\n",
       "       'numerical_imputer__OpenPorchSF',\n",
       "       'numerical_imputer__EnclosedPorch', 'numerical_imputer__3SsnPorch',\n",
       "       'numerical_imputer__ScreenPorch', 'numerical_imputer__PoolArea',\n",
       "       'numerical_imputer__MiscVal', 'numerical_imputer__MoSold',\n",
       "       'numerical_imputer__YrSold'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model = lr_pipeline[\"model\"]\n",
    "intercept = lr_model.intercept_\n",
    "coeffs = lr_model.coef_\n",
    "feature_names = lr_pipeline[\"preprocessor\"].get_feature_names_out()\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c694b510",
   "metadata": {},
   "source": [
    "<span style=\"color: blue;\"><strong>Notes:</strong></span>\n",
    "- All features are numerical as is indicated by the feature names extracted from the fitted ColumnTransformer\n",
    "- For better inspection, we extract the original feature names from them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "65a07f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beta_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>intercept</th>\n",
       "      <td>18.140570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSSubClass</th>\n",
       "      <td>-0.000733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotFrontage</th>\n",
       "      <td>-0.000273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotArea</th>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OverallQual</th>\n",
       "      <td>0.087042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OverallCond</th>\n",
       "      <td>0.048559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YearBuilt</th>\n",
       "      <td>0.003062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <td>0.000961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MasVnrArea</th>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1stFlrSF</th>\n",
       "      <td>0.000056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <td>0.000029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LowQualFinSF</th>\n",
       "      <td>0.000051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GrLivArea</th>\n",
       "      <td>0.000136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <td>0.067200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <td>0.027456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FullBath</th>\n",
       "      <td>0.043413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HalfBath</th>\n",
       "      <td>0.009781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <td>-0.008155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <td>-0.073766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <td>0.020769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fireplaces</th>\n",
       "      <td>0.039261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <td>-0.000133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageCars</th>\n",
       "      <td>0.077228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageArea</th>\n",
       "      <td>-0.000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <td>0.000179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <td>0.000095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <td>0.000178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3SsnPorch</th>\n",
       "      <td>0.000286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ScreenPorch</th>\n",
       "      <td>0.000363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PoolArea</th>\n",
       "      <td>-0.000351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MiscVal</th>\n",
       "      <td>-0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MoSold</th>\n",
       "      <td>0.002024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YrSold</th>\n",
       "      <td>-0.007569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                beta_hat\n",
       "intercept      18.140570\n",
       "MSSubClass     -0.000733\n",
       "LotFrontage    -0.000273\n",
       "LotArea         0.000002\n",
       "OverallQual     0.087042\n",
       "OverallCond     0.048559\n",
       "YearBuilt       0.003062\n",
       "YearRemodAdd    0.000961\n",
       "MasVnrArea      0.000003\n",
       "BsmtFinSF1      0.000018\n",
       "BsmtFinSF2      0.000002\n",
       "BsmtUnfSF       0.000001\n",
       "TotalBsmtSF     0.000022\n",
       "1stFlrSF        0.000056\n",
       "2ndFlrSF        0.000029\n",
       "LowQualFinSF    0.000051\n",
       "GrLivArea       0.000136\n",
       "BsmtFullBath    0.067200\n",
       "BsmtHalfBath    0.027456\n",
       "FullBath        0.043413\n",
       "HalfBath        0.009781\n",
       "BedroomAbvGr   -0.008155\n",
       "KitchenAbvGr   -0.073766\n",
       "TotRmsAbvGrd    0.020769\n",
       "Fireplaces      0.039261\n",
       "GarageYrBlt    -0.000133\n",
       "GarageCars      0.077228\n",
       "GarageArea     -0.000026\n",
       "WoodDeckSF      0.000179\n",
       "OpenPorchSF     0.000095\n",
       "EnclosedPorch   0.000178\n",
       "3SsnPorch       0.000286\n",
       "ScreenPorch     0.000363\n",
       "PoolArea       -0.000351\n",
       "MiscVal        -0.000002\n",
       "MoSold          0.002024\n",
       "YrSold         -0.007569"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_hats_df = pd.DataFrame(\n",
    "    [intercept] + list(coeffs),\n",
    "    index=[\"intercept\"] + list(map(lambda feat_name: feat_name.split(\"__\")[1], feature_names)),\n",
    "    columns=[\"beta_hat\"]\n",
    ")\n",
    "beta_hats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9c30340e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mean_squared_error'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f8d1e150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>r2_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>in-sample</th>\n",
       "      <td>0.021603</td>\n",
       "      <td>0.861617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out-of-sample</th>\n",
       "      <td>0.020817</td>\n",
       "      <td>0.875258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               mean_squared_error  r2_score\n",
       "in-sample                0.021603  0.861617\n",
       "out-of-sample            0.020817  0.875258"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compare the in-sample and out-of-sample Mean Squared Error (MSE) and R^2 of your linear regression model.\n",
    "def compute_metrics(metric_funcs: List[Callable], model: BaseEstimator, X_train, y_train, X_test, y_test):\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    metrics_dict = defaultdict(list)\n",
    "    for y_pred_iter, y_iter in zip([y_pred_train, y_pred_test], [y_train, y_test]):\n",
    "        for metric_func in metric_funcs:\n",
    "            metrics_dict[metric_func.__name__].append(metric_func(y_iter, y_pred_iter))\n",
    "    metrics_df = pd.DataFrame(metrics_dict, index=[\"in-sample\", \"out-of-sample\"])\n",
    "    \n",
    "    return metrics_df\n",
    "\n",
    "metrics_df = compute_metrics(\n",
    "    [mean_squared_error, r2_score],\n",
    "    lr_pipeline,\n",
    "    X_train_numerical,\n",
    "    y_train,\n",
    "    X_test_numerical,\n",
    "    y_test\n",
    ")\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f03e0b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.c) (i) Compute the estimated coefficients for each explanatory variable using the numpy package. Remember that the design matrix A needs to include a column of 1's.\n",
    "\n",
    "#\t  (ii) Compute the standard error of each estimated coefficient using the numpy package.\n",
    "\n",
    "#     (iii) Compute the (in-sample) MSE and R^2 using the numpy package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "93295052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1022, 37), (1022,))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill NA in the training set, i.e. using an identity model for create_pipeline(.)\n",
    "pass_through_pipeline = create_pipeline(FunctionTransformer())\n",
    "X_train_numerical_tfm = pass_through_pipeline.fit_transform(X_train_numerical)\n",
    "X_train_mat = np.concatenate([np.ones((X_train_numerical_tfm.shape[0], 1)), X_train_numerical_tfm], axis=1)\n",
    "y_train_mat = y_train.values\n",
    "feature_names = [\"Intercept\"] + list(X_train_numerical.columns)\n",
    "X_train_mat.shape, y_train_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "47fc4416",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression_inference(X_train: np.ndarray, y_train: np.ndarray, feature_names: Iterable, inv_func: Callable):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    inv_func: Callable\n",
    "        Either np.linalg.inv(.) or np.linalg.pinv(.)\n",
    "    \"\"\"\n",
    "    m, l = X_train.shape\n",
    "    X_T_X_inv = inv_func(X_train.T @ X_train)\n",
    "    \n",
    "    # Estimate beta\n",
    "    beta_hat = X_T_X_inv @ (X_train.T @ y_train)\n",
    "    \n",
    "    # Compute SE and T-statistic\n",
    "    y_pred = X_train @ beta_hat\n",
    "    SSE = ((y_pred - y_train) ** 2).sum()\n",
    "    sigma_sq_hat = SSE / (m - l)\n",
    "    se = np.sqrt(sigma_sq_hat * np.diag(X_T_X_inv))\n",
    "    t_stat = beta_hat / se\n",
    "    est_df = pd.DataFrame(\n",
    "        {\n",
    "            \"beta_hat\": beta_hat, \n",
    "            \"SE\": se,\n",
    "            \"t_stat\": t_stat,\n",
    "        },\n",
    "        index=feature_names\n",
    "    )\n",
    "    \n",
    "    # Compute in-sample MSE and R^2\n",
    "    y_train_mean = y_train.mean()\n",
    "    SST = ((y_train - y_train_mean) ** 2).sum()\n",
    "    metrics = {}\n",
    "    metrics[\"MSE\"] = SSE / m  # More precisely, / (m - l)\n",
    "    metrics[\"R^2\"] = 1 - SSE / SST\n",
    "    \n",
    "    return est_df, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b460e2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MSE': 4852.295926141039, 'R^2': -31081.68265359521}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_3484\\172047323.py:18: RuntimeWarning: invalid value encountered in sqrt\n",
      "  se = np.sqrt(sigma_sq_hat * np.diag(X_T_X_inv))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beta_hat</th>\n",
       "      <th>SE</th>\n",
       "      <th>t_stat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Intercept</th>\n",
       "      <td>3.299439e+03</td>\n",
       "      <td>3516.194229</td>\n",
       "      <td>0.938355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSSubClass</th>\n",
       "      <td>-5.753126e-01</td>\n",
       "      <td>0.067790</td>\n",
       "      <td>-8.486746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotFrontage</th>\n",
       "      <td>-1.471720e+00</td>\n",
       "      <td>0.124501</td>\n",
       "      <td>-11.820920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotArea</th>\n",
       "      <td>2.122109e-04</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.961052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OverallQual</th>\n",
       "      <td>2.780274e+01</td>\n",
       "      <td>2.951978</td>\n",
       "      <td>9.418340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OverallCond</th>\n",
       "      <td>-1.309736e+01</td>\n",
       "      <td>2.528957</td>\n",
       "      <td>-5.178954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YearBuilt</th>\n",
       "      <td>-1.871789e+00</td>\n",
       "      <td>0.162037</td>\n",
       "      <td>-11.551636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <td>2.311180e-01</td>\n",
       "      <td>0.168261</td>\n",
       "      <td>1.373565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MasVnrArea</th>\n",
       "      <td>1.519903e-02</td>\n",
       "      <td>0.014080</td>\n",
       "      <td>1.079448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <td>-2.131417e+11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <td>-2.131417e+11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <td>-2.131417e+11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <td>2.131417e+11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1stFlrSF</th>\n",
       "      <td>-7.462088e-03</td>\n",
       "      <td>0.098590</td>\n",
       "      <td>-0.075688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <td>-7.113569e-03</td>\n",
       "      <td>0.096826</td>\n",
       "      <td>-0.073468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LowQualFinSF</th>\n",
       "      <td>1.496788e-03</td>\n",
       "      <td>0.117148</td>\n",
       "      <td>0.012777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GrLivArea</th>\n",
       "      <td>2.711587e-02</td>\n",
       "      <td>0.099589</td>\n",
       "      <td>0.272279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <td>6.720037e-02</td>\n",
       "      <td>6.493335</td>\n",
       "      <td>0.010349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <td>2.745633e-02</td>\n",
       "      <td>10.371667</td>\n",
       "      <td>0.002647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FullBath</th>\n",
       "      <td>4.341326e-02</td>\n",
       "      <td>7.017234</td>\n",
       "      <td>0.006187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HalfBath</th>\n",
       "      <td>9.780747e-03</td>\n",
       "      <td>6.684065</td>\n",
       "      <td>0.001463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <td>-8.155159e-03</td>\n",
       "      <td>4.255074</td>\n",
       "      <td>-0.001917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <td>-7.376552e-02</td>\n",
       "      <td>13.727942</td>\n",
       "      <td>-0.005373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <td>2.076864e-02</td>\n",
       "      <td>3.073022</td>\n",
       "      <td>0.006758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fireplaces</th>\n",
       "      <td>3.926122e-02</td>\n",
       "      <td>4.324485</td>\n",
       "      <td>0.009079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <td>-1.334901e-04</td>\n",
       "      <td>0.169974</td>\n",
       "      <td>-0.000785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageCars</th>\n",
       "      <td>7.722819e-02</td>\n",
       "      <td>6.871367</td>\n",
       "      <td>0.011239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageArea</th>\n",
       "      <td>-2.579070e-05</td>\n",
       "      <td>0.024003</td>\n",
       "      <td>-0.001074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <td>1.785446e-04</td>\n",
       "      <td>0.019648</td>\n",
       "      <td>0.009087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <td>9.498909e-05</td>\n",
       "      <td>0.037640</td>\n",
       "      <td>0.002524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <td>1.781813e-04</td>\n",
       "      <td>0.040900</td>\n",
       "      <td>0.004357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3SsnPorch</th>\n",
       "      <td>2.864934e-04</td>\n",
       "      <td>0.070038</td>\n",
       "      <td>0.004091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ScreenPorch</th>\n",
       "      <td>3.625896e-04</td>\n",
       "      <td>0.045664</td>\n",
       "      <td>0.007940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PoolArea</th>\n",
       "      <td>-3.514395e-04</td>\n",
       "      <td>0.059883</td>\n",
       "      <td>-0.005869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MiscVal</th>\n",
       "      <td>-1.580279e-06</td>\n",
       "      <td>0.003858</td>\n",
       "      <td>-0.000410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MoSold</th>\n",
       "      <td>2.024464e-03</td>\n",
       "      <td>0.838157</td>\n",
       "      <td>0.002415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YrSold</th>\n",
       "      <td>-7.569489e-03</td>\n",
       "      <td>1.748622</td>\n",
       "      <td>-0.004329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   beta_hat           SE     t_stat\n",
       "Intercept      3.299439e+03  3516.194229   0.938355\n",
       "MSSubClass    -5.753126e-01     0.067790  -8.486746\n",
       "LotFrontage   -1.471720e+00     0.124501 -11.820920\n",
       "LotArea        2.122109e-04     0.000221   0.961052\n",
       "OverallQual    2.780274e+01     2.951978   9.418340\n",
       "OverallCond   -1.309736e+01     2.528957  -5.178954\n",
       "YearBuilt     -1.871789e+00     0.162037 -11.551636\n",
       "YearRemodAdd   2.311180e-01     0.168261   1.373565\n",
       "MasVnrArea     1.519903e-02     0.014080   1.079448\n",
       "BsmtFinSF1    -2.131417e+11          NaN        NaN\n",
       "BsmtFinSF2    -2.131417e+11          NaN        NaN\n",
       "BsmtUnfSF     -2.131417e+11          NaN        NaN\n",
       "TotalBsmtSF    2.131417e+11          NaN        NaN\n",
       "1stFlrSF      -7.462088e-03     0.098590  -0.075688\n",
       "2ndFlrSF      -7.113569e-03     0.096826  -0.073468\n",
       "LowQualFinSF   1.496788e-03     0.117148   0.012777\n",
       "GrLivArea      2.711587e-02     0.099589   0.272279\n",
       "BsmtFullBath   6.720037e-02     6.493335   0.010349\n",
       "BsmtHalfBath   2.745633e-02    10.371667   0.002647\n",
       "FullBath       4.341326e-02     7.017234   0.006187\n",
       "HalfBath       9.780747e-03     6.684065   0.001463\n",
       "BedroomAbvGr  -8.155159e-03     4.255074  -0.001917\n",
       "KitchenAbvGr  -7.376552e-02    13.727942  -0.005373\n",
       "TotRmsAbvGrd   2.076864e-02     3.073022   0.006758\n",
       "Fireplaces     3.926122e-02     4.324485   0.009079\n",
       "GarageYrBlt   -1.334901e-04     0.169974  -0.000785\n",
       "GarageCars     7.722819e-02     6.871367   0.011239\n",
       "GarageArea    -2.579070e-05     0.024003  -0.001074\n",
       "WoodDeckSF     1.785446e-04     0.019648   0.009087\n",
       "OpenPorchSF    9.498909e-05     0.037640   0.002524\n",
       "EnclosedPorch  1.781813e-04     0.040900   0.004357\n",
       "3SsnPorch      2.864934e-04     0.070038   0.004091\n",
       "ScreenPorch    3.625896e-04     0.045664   0.007940\n",
       "PoolArea      -3.514395e-04     0.059883  -0.005869\n",
       "MiscVal       -1.580279e-06     0.003858  -0.000410\n",
       "MoSold         2.024464e-03     0.838157   0.002415\n",
       "YrSold        -7.569489e-03     1.748622  -0.004329"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.linalg.inv(.)\n",
    "est_inv, metrics_inv = linear_regression_inference(\n",
    "    X_train_mat,\n",
    "    y_train_mat,\n",
    "    feature_names,\n",
    "    np.linalg.inv\n",
    ")\n",
    "print(metrics_inv)\n",
    "est_inv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4d4802",
   "metadata": {},
   "source": [
    "<span style=\"color: blue;\"><strong>Note:</strong></span>\n",
    "Results using standard matrix inversion are shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "da401fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MSE': 0.02160292026600646, 'R^2': 0.8616167016109393}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beta_hat</th>\n",
       "      <th>SE</th>\n",
       "      <th>t_stat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Intercept</th>\n",
       "      <td>18.140446</td>\n",
       "      <td>7.419173e+00</td>\n",
       "      <td>2.445076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSSubClass</th>\n",
       "      <td>-0.000733</td>\n",
       "      <td>1.430360e-04</td>\n",
       "      <td>-5.121529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotFrontage</th>\n",
       "      <td>-0.000273</td>\n",
       "      <td>2.626978e-04</td>\n",
       "      <td>-1.038682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotArea</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>4.659113e-07</td>\n",
       "      <td>3.881226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OverallQual</th>\n",
       "      <td>0.087042</td>\n",
       "      <td>6.228676e-03</td>\n",
       "      <td>13.974441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OverallCond</th>\n",
       "      <td>0.048559</td>\n",
       "      <td>5.336102e-03</td>\n",
       "      <td>9.100130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YearBuilt</th>\n",
       "      <td>0.003062</td>\n",
       "      <td>3.418976e-04</td>\n",
       "      <td>8.955720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <td>0.000961</td>\n",
       "      <td>3.550318e-04</td>\n",
       "      <td>2.707686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MasVnrArea</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>2.970960e-05</td>\n",
       "      <td>0.114042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <td>0.000018</td>\n",
       "      <td>1.330468e-05</td>\n",
       "      <td>1.386096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>2.489113e-05</td>\n",
       "      <td>0.084359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.286437e-05</td>\n",
       "      <td>0.102890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <td>0.000022</td>\n",
       "      <td>1.802014e-05</td>\n",
       "      <td>1.213664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1stFlrSF</th>\n",
       "      <td>0.000056</td>\n",
       "      <td>3.066240e-05</td>\n",
       "      <td>1.831313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <td>0.000029</td>\n",
       "      <td>2.851647e-05</td>\n",
       "      <td>1.009828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LowQualFinSF</th>\n",
       "      <td>0.000051</td>\n",
       "      <td>7.162001e-05</td>\n",
       "      <td>0.709106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GrLivArea</th>\n",
       "      <td>0.000136</td>\n",
       "      <td>2.755753e-05</td>\n",
       "      <td>4.925973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <td>0.067200</td>\n",
       "      <td>1.370094e-02</td>\n",
       "      <td>4.904798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <td>0.027456</td>\n",
       "      <td>2.188422e-02</td>\n",
       "      <td>1.254618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FullBath</th>\n",
       "      <td>0.043413</td>\n",
       "      <td>1.480637e-02</td>\n",
       "      <td>2.932066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HalfBath</th>\n",
       "      <td>0.009781</td>\n",
       "      <td>1.410338e-02</td>\n",
       "      <td>0.693503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <td>-0.008155</td>\n",
       "      <td>8.978209e-03</td>\n",
       "      <td>-0.908327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <td>-0.073766</td>\n",
       "      <td>2.896597e-02</td>\n",
       "      <td>-2.546627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <td>0.020769</td>\n",
       "      <td>6.484079e-03</td>\n",
       "      <td>3.203022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fireplaces</th>\n",
       "      <td>0.039261</td>\n",
       "      <td>9.124666e-03</td>\n",
       "      <td>4.302756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <td>-0.000133</td>\n",
       "      <td>3.586462e-04</td>\n",
       "      <td>-0.372205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageCars</th>\n",
       "      <td>0.077228</td>\n",
       "      <td>1.449859e-02</td>\n",
       "      <td>5.326601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageArea</th>\n",
       "      <td>-0.000026</td>\n",
       "      <td>5.064566e-05</td>\n",
       "      <td>-0.509239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <td>0.000179</td>\n",
       "      <td>4.145761e-05</td>\n",
       "      <td>4.306678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <td>0.000095</td>\n",
       "      <td>7.942046e-05</td>\n",
       "      <td>1.196029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <td>0.000178</td>\n",
       "      <td>8.629810e-05</td>\n",
       "      <td>2.064719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3SsnPorch</th>\n",
       "      <td>0.000286</td>\n",
       "      <td>1.477808e-04</td>\n",
       "      <td>1.938638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ScreenPorch</th>\n",
       "      <td>0.000363</td>\n",
       "      <td>9.635005e-05</td>\n",
       "      <td>3.763253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PoolArea</th>\n",
       "      <td>-0.000351</td>\n",
       "      <td>1.263526e-04</td>\n",
       "      <td>-2.781418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MiscVal</th>\n",
       "      <td>-0.000002</td>\n",
       "      <td>8.141226e-06</td>\n",
       "      <td>-0.194108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MoSold</th>\n",
       "      <td>0.002024</td>\n",
       "      <td>1.768512e-03</td>\n",
       "      <td>1.144730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YrSold</th>\n",
       "      <td>-0.007569</td>\n",
       "      <td>3.689595e-03</td>\n",
       "      <td>-2.051560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                beta_hat            SE     t_stat\n",
       "Intercept      18.140446  7.419173e+00   2.445076\n",
       "MSSubClass     -0.000733  1.430360e-04  -5.121529\n",
       "LotFrontage    -0.000273  2.626978e-04  -1.038682\n",
       "LotArea         0.000002  4.659113e-07   3.881226\n",
       "OverallQual     0.087042  6.228676e-03  13.974441\n",
       "OverallCond     0.048559  5.336102e-03   9.100130\n",
       "YearBuilt       0.003062  3.418976e-04   8.955720\n",
       "YearRemodAdd    0.000961  3.550318e-04   2.707686\n",
       "MasVnrArea      0.000003  2.970960e-05   0.114042\n",
       "BsmtFinSF1      0.000018  1.330468e-05   1.386096\n",
       "BsmtFinSF2      0.000002  2.489113e-05   0.084359\n",
       "BsmtUnfSF       0.000001  1.286437e-05   0.102890\n",
       "TotalBsmtSF     0.000022  1.802014e-05   1.213664\n",
       "1stFlrSF        0.000056  3.066240e-05   1.831313\n",
       "2ndFlrSF        0.000029  2.851647e-05   1.009828\n",
       "LowQualFinSF    0.000051  7.162001e-05   0.709106\n",
       "GrLivArea       0.000136  2.755753e-05   4.925973\n",
       "BsmtFullBath    0.067200  1.370094e-02   4.904798\n",
       "BsmtHalfBath    0.027456  2.188422e-02   1.254618\n",
       "FullBath        0.043413  1.480637e-02   2.932066\n",
       "HalfBath        0.009781  1.410338e-02   0.693503\n",
       "BedroomAbvGr   -0.008155  8.978209e-03  -0.908327\n",
       "KitchenAbvGr   -0.073766  2.896597e-02  -2.546627\n",
       "TotRmsAbvGrd    0.020769  6.484079e-03   3.203022\n",
       "Fireplaces      0.039261  9.124666e-03   4.302756\n",
       "GarageYrBlt    -0.000133  3.586462e-04  -0.372205\n",
       "GarageCars      0.077228  1.449859e-02   5.326601\n",
       "GarageArea     -0.000026  5.064566e-05  -0.509239\n",
       "WoodDeckSF      0.000179  4.145761e-05   4.306678\n",
       "OpenPorchSF     0.000095  7.942046e-05   1.196029\n",
       "EnclosedPorch   0.000178  8.629810e-05   2.064719\n",
       "3SsnPorch       0.000286  1.477808e-04   1.938638\n",
       "ScreenPorch     0.000363  9.635005e-05   3.763253\n",
       "PoolArea       -0.000351  1.263526e-04  -2.781418\n",
       "MiscVal        -0.000002  8.141226e-06  -0.194108\n",
       "MoSold          0.002024  1.768512e-03   1.144730\n",
       "YrSold         -0.007569  3.689595e-03  -2.051560"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.linalg.pinv(.)\n",
    "est_pinv, metrics_pinv = linear_regression_inference(\n",
    "    X_train_mat,\n",
    "    y_train_mat,\n",
    "    feature_names,\n",
    "    np.linalg.pinv\n",
    ")\n",
    "print(metrics_pinv)\n",
    "est_pinv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a7f23f",
   "metadata": {},
   "source": [
    "<span style=\"color: blue;\"><strong>Note:</strong></span>\n",
    "Results using pseudo-inversion are shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "91c42e9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(est_pinv[\"beta_hat\"], beta_hats_df[\"beta_hat\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9584c961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35, (1022, 37))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.matrix_rank(X_train_mat), X_train_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "05f77d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     (iv) Do the results change using pseudoinversion instead of standard matrix inversion in (i) and (ii)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893db0e2",
   "metadata": {},
   "source": [
    "<span style=\"color: blue;\"><strong>Discussion:</strong></span>\n",
    "1. We see different results from using inverse and pseudo-inverse\n",
    "1. The result from using inverse doesn't make sense, because the training matrix is singular, i.e. it has rank 35 but there are 37 columns\n",
    "1. The result from using pseudo-inverse agrees with the result from `sklearn.linear_model.LinearRegression`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e033e45e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.862</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.857</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   180.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 27 Sep 2024</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:39:05</td>     <th>  Log-Likelihood:    </th> <td>  509.49</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1022</td>      <th>  AIC:               </th> <td>  -949.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   987</td>      <th>  BIC:               </th> <td>  -776.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    34</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   18.1406</td> <td>    7.412</td> <td>    2.448</td> <td> 0.015</td> <td>    3.596</td> <td>   32.685</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -0.0007</td> <td>    0.000</td> <td>   -5.127</td> <td> 0.000</td> <td>   -0.001</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -0.0003</td> <td>    0.000</td> <td>   -1.040</td> <td> 0.299</td> <td>   -0.001</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td> 1.808e-06</td> <td> 4.65e-07</td> <td>    3.885</td> <td> 0.000</td> <td> 8.95e-07</td> <td> 2.72e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.0870</td> <td>    0.006</td> <td>   13.989</td> <td> 0.000</td> <td>    0.075</td> <td>    0.099</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    0.0486</td> <td>    0.005</td> <td>    9.109</td> <td> 0.000</td> <td>    0.038</td> <td>    0.059</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    0.0031</td> <td>    0.000</td> <td>    8.965</td> <td> 0.000</td> <td>    0.002</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    0.0010</td> <td>    0.000</td> <td>    2.710</td> <td> 0.007</td> <td>    0.000</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td> 3.388e-06</td> <td> 2.97e-05</td> <td>    0.114</td> <td> 0.909</td> <td>-5.49e-05</td> <td> 6.16e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td> 1.844e-05</td> <td> 1.33e-05</td> <td>    1.389</td> <td> 0.165</td> <td>-7.61e-06</td> <td> 4.45e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td> 2.101e-06</td> <td> 2.49e-05</td> <td>    0.084</td> <td> 0.933</td> <td>-4.67e-05</td> <td> 5.09e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td> 1.325e-06</td> <td> 1.29e-05</td> <td>    0.103</td> <td> 0.918</td> <td>-2.39e-05</td> <td> 2.66e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td> 2.187e-05</td> <td>  1.8e-05</td> <td>    1.215</td> <td> 0.225</td> <td>-1.34e-05</td> <td> 5.72e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td> 5.616e-05</td> <td> 3.06e-05</td> <td>    1.833</td> <td> 0.067</td> <td>-3.95e-06</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>  2.88e-05</td> <td> 2.85e-05</td> <td>    1.011</td> <td> 0.312</td> <td>-2.71e-05</td> <td> 8.47e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td> 5.079e-05</td> <td> 7.16e-05</td> <td>    0.710</td> <td> 0.478</td> <td>-8.96e-05</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td>    0.0001</td> <td> 2.75e-05</td> <td>    4.933</td> <td> 0.000</td> <td> 8.17e-05</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td>    0.0672</td> <td>    0.014</td> <td>    4.910</td> <td> 0.000</td> <td>    0.040</td> <td>    0.094</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td>    0.0275</td> <td>    0.022</td> <td>    1.256</td> <td> 0.209</td> <td>   -0.015</td> <td>    0.070</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td>    0.0434</td> <td>    0.015</td> <td>    2.935</td> <td> 0.003</td> <td>    0.014</td> <td>    0.072</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>   <td>    0.0098</td> <td>    0.014</td> <td>    0.694</td> <td> 0.488</td> <td>   -0.018</td> <td>    0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th>   <td>   -0.0082</td> <td>    0.009</td> <td>   -0.909</td> <td> 0.363</td> <td>   -0.026</td> <td>    0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th>   <td>   -0.0738</td> <td>    0.029</td> <td>   -2.549</td> <td> 0.011</td> <td>   -0.131</td> <td>   -0.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23</th>   <td>    0.0208</td> <td>    0.006</td> <td>    3.206</td> <td> 0.001</td> <td>    0.008</td> <td>    0.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24</th>   <td>    0.0393</td> <td>    0.009</td> <td>    4.307</td> <td> 0.000</td> <td>    0.021</td> <td>    0.057</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25</th>   <td>   -0.0001</td> <td>    0.000</td> <td>   -0.373</td> <td> 0.710</td> <td>   -0.001</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26</th>   <td>    0.0772</td> <td>    0.014</td> <td>    5.332</td> <td> 0.000</td> <td>    0.049</td> <td>    0.106</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27</th>   <td>-2.579e-05</td> <td> 5.06e-05</td> <td>   -0.510</td> <td> 0.610</td> <td>   -0.000</td> <td> 7.35e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28</th>   <td>    0.0002</td> <td> 4.14e-05</td> <td>    4.311</td> <td> 0.000</td> <td> 9.73e-05</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x29</th>   <td> 9.499e-05</td> <td> 7.93e-05</td> <td>    1.197</td> <td> 0.231</td> <td>-6.07e-05</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x30</th>   <td>    0.0002</td> <td> 8.62e-05</td> <td>    2.067</td> <td> 0.039</td> <td>    9e-06</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x31</th>   <td>    0.0003</td> <td>    0.000</td> <td>    1.941</td> <td> 0.053</td> <td>-3.21e-06</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x32</th>   <td>    0.0004</td> <td> 9.63e-05</td> <td>    3.767</td> <td> 0.000</td> <td>    0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x33</th>   <td>   -0.0004</td> <td>    0.000</td> <td>   -2.784</td> <td> 0.005</td> <td>   -0.001</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x34</th>   <td> -1.58e-06</td> <td> 8.13e-06</td> <td>   -0.194</td> <td> 0.846</td> <td>-1.75e-05</td> <td> 1.44e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x35</th>   <td>    0.0020</td> <td>    0.002</td> <td>    1.146</td> <td> 0.252</td> <td>   -0.001</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x36</th>   <td>   -0.0076</td> <td>    0.004</td> <td>   -2.054</td> <td> 0.040</td> <td>   -0.015</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>712.487</td> <th>  Durbin-Watson:     </th> <td>   1.933</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>30101.499</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-2.650</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>29.054</td>  <th>  Cond. No.          </th> <td>1.37e+16</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 1.38e-21. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     0.862   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.857   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     180.7   \\\\\n",
       "\\textbf{Date:}             & Fri, 27 Sep 2024 & \\textbf{  Prob (F-statistic):} &     0.00    \\\\\n",
       "\\textbf{Time:}             &     17:39:05     & \\textbf{  Log-Likelihood:    } &    509.49   \\\\\n",
       "\\textbf{No. Observations:} &        1022      & \\textbf{  AIC:               } &    -949.0   \\\\\n",
       "\\textbf{Df Residuals:}     &         987      & \\textbf{  BIC:               } &    -776.5   \\\\\n",
       "\\textbf{Df Model:}         &          34      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &      18.1406  &        7.412     &     2.448  &         0.015        &        3.596    &       32.685     \\\\\n",
       "\\textbf{x1}    &      -0.0007  &        0.000     &    -5.127  &         0.000        &       -0.001    &       -0.000     \\\\\n",
       "\\textbf{x2}    &      -0.0003  &        0.000     &    -1.040  &         0.299        &       -0.001    &        0.000     \\\\\n",
       "\\textbf{x3}    &    1.808e-06  &     4.65e-07     &     3.885  &         0.000        &     8.95e-07    &     2.72e-06     \\\\\n",
       "\\textbf{x4}    &       0.0870  &        0.006     &    13.989  &         0.000        &        0.075    &        0.099     \\\\\n",
       "\\textbf{x5}    &       0.0486  &        0.005     &     9.109  &         0.000        &        0.038    &        0.059     \\\\\n",
       "\\textbf{x6}    &       0.0031  &        0.000     &     8.965  &         0.000        &        0.002    &        0.004     \\\\\n",
       "\\textbf{x7}    &       0.0010  &        0.000     &     2.710  &         0.007        &        0.000    &        0.002     \\\\\n",
       "\\textbf{x8}    &    3.388e-06  &     2.97e-05     &     0.114  &         0.909        &    -5.49e-05    &     6.16e-05     \\\\\n",
       "\\textbf{x9}    &    1.844e-05  &     1.33e-05     &     1.389  &         0.165        &    -7.61e-06    &     4.45e-05     \\\\\n",
       "\\textbf{x10}   &    2.101e-06  &     2.49e-05     &     0.084  &         0.933        &    -4.67e-05    &     5.09e-05     \\\\\n",
       "\\textbf{x11}   &    1.325e-06  &     1.29e-05     &     0.103  &         0.918        &    -2.39e-05    &     2.66e-05     \\\\\n",
       "\\textbf{x12}   &    2.187e-05  &      1.8e-05     &     1.215  &         0.225        &    -1.34e-05    &     5.72e-05     \\\\\n",
       "\\textbf{x13}   &    5.616e-05  &     3.06e-05     &     1.833  &         0.067        &    -3.95e-06    &        0.000     \\\\\n",
       "\\textbf{x14}   &     2.88e-05  &     2.85e-05     &     1.011  &         0.312        &    -2.71e-05    &     8.47e-05     \\\\\n",
       "\\textbf{x15}   &    5.079e-05  &     7.16e-05     &     0.710  &         0.478        &    -8.96e-05    &        0.000     \\\\\n",
       "\\textbf{x16}   &       0.0001  &     2.75e-05     &     4.933  &         0.000        &     8.17e-05    &        0.000     \\\\\n",
       "\\textbf{x17}   &       0.0672  &        0.014     &     4.910  &         0.000        &        0.040    &        0.094     \\\\\n",
       "\\textbf{x18}   &       0.0275  &        0.022     &     1.256  &         0.209        &       -0.015    &        0.070     \\\\\n",
       "\\textbf{x19}   &       0.0434  &        0.015     &     2.935  &         0.003        &        0.014    &        0.072     \\\\\n",
       "\\textbf{x20}   &       0.0098  &        0.014     &     0.694  &         0.488        &       -0.018    &        0.037     \\\\\n",
       "\\textbf{x21}   &      -0.0082  &        0.009     &    -0.909  &         0.363        &       -0.026    &        0.009     \\\\\n",
       "\\textbf{x22}   &      -0.0738  &        0.029     &    -2.549  &         0.011        &       -0.131    &       -0.017     \\\\\n",
       "\\textbf{x23}   &       0.0208  &        0.006     &     3.206  &         0.001        &        0.008    &        0.033     \\\\\n",
       "\\textbf{x24}   &       0.0393  &        0.009     &     4.307  &         0.000        &        0.021    &        0.057     \\\\\n",
       "\\textbf{x25}   &      -0.0001  &        0.000     &    -0.373  &         0.710        &       -0.001    &        0.001     \\\\\n",
       "\\textbf{x26}   &       0.0772  &        0.014     &     5.332  &         0.000        &        0.049    &        0.106     \\\\\n",
       "\\textbf{x27}   &   -2.579e-05  &     5.06e-05     &    -0.510  &         0.610        &       -0.000    &     7.35e-05     \\\\\n",
       "\\textbf{x28}   &       0.0002  &     4.14e-05     &     4.311  &         0.000        &     9.73e-05    &        0.000     \\\\\n",
       "\\textbf{x29}   &    9.499e-05  &     7.93e-05     &     1.197  &         0.231        &    -6.07e-05    &        0.000     \\\\\n",
       "\\textbf{x30}   &       0.0002  &     8.62e-05     &     2.067  &         0.039        &        9e-06    &        0.000     \\\\\n",
       "\\textbf{x31}   &       0.0003  &        0.000     &     1.941  &         0.053        &    -3.21e-06    &        0.001     \\\\\n",
       "\\textbf{x32}   &       0.0004  &     9.63e-05     &     3.767  &         0.000        &        0.000    &        0.001     \\\\\n",
       "\\textbf{x33}   &      -0.0004  &        0.000     &    -2.784  &         0.005        &       -0.001    &       -0.000     \\\\\n",
       "\\textbf{x34}   &    -1.58e-06  &     8.13e-06     &    -0.194  &         0.846        &    -1.75e-05    &     1.44e-05     \\\\\n",
       "\\textbf{x35}   &       0.0020  &        0.002     &     1.146  &         0.252        &       -0.001    &        0.005     \\\\\n",
       "\\textbf{x36}   &      -0.0076  &        0.004     &    -2.054  &         0.040        &       -0.015    &       -0.000     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 712.487 & \\textbf{  Durbin-Watson:     } &     1.933  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 30101.499  \\\\\n",
       "\\textbf{Skew:}          &  -2.650 & \\textbf{  Prob(JB):          } &      0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  29.054 & \\textbf{  Cond. No.          } &  1.37e+16  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The smallest eigenvalue is 1.38e-21. This might indicate that there are \\newline\n",
       " strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.862\n",
       "Model:                            OLS   Adj. R-squared:                  0.857\n",
       "Method:                 Least Squares   F-statistic:                     180.7\n",
       "Date:                Fri, 27 Sep 2024   Prob (F-statistic):               0.00\n",
       "Time:                        17:39:05   Log-Likelihood:                 509.49\n",
       "No. Observations:                1022   AIC:                            -949.0\n",
       "Df Residuals:                     987   BIC:                            -776.5\n",
       "Df Model:                          34                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         18.1406      7.412      2.448      0.015       3.596      32.685\n",
       "x1            -0.0007      0.000     -5.127      0.000      -0.001      -0.000\n",
       "x2            -0.0003      0.000     -1.040      0.299      -0.001       0.000\n",
       "x3          1.808e-06   4.65e-07      3.885      0.000    8.95e-07    2.72e-06\n",
       "x4             0.0870      0.006     13.989      0.000       0.075       0.099\n",
       "x5             0.0486      0.005      9.109      0.000       0.038       0.059\n",
       "x6             0.0031      0.000      8.965      0.000       0.002       0.004\n",
       "x7             0.0010      0.000      2.710      0.007       0.000       0.002\n",
       "x8          3.388e-06   2.97e-05      0.114      0.909   -5.49e-05    6.16e-05\n",
       "x9          1.844e-05   1.33e-05      1.389      0.165   -7.61e-06    4.45e-05\n",
       "x10         2.101e-06   2.49e-05      0.084      0.933   -4.67e-05    5.09e-05\n",
       "x11         1.325e-06   1.29e-05      0.103      0.918   -2.39e-05    2.66e-05\n",
       "x12         2.187e-05    1.8e-05      1.215      0.225   -1.34e-05    5.72e-05\n",
       "x13         5.616e-05   3.06e-05      1.833      0.067   -3.95e-06       0.000\n",
       "x14          2.88e-05   2.85e-05      1.011      0.312   -2.71e-05    8.47e-05\n",
       "x15         5.079e-05   7.16e-05      0.710      0.478   -8.96e-05       0.000\n",
       "x16            0.0001   2.75e-05      4.933      0.000    8.17e-05       0.000\n",
       "x17            0.0672      0.014      4.910      0.000       0.040       0.094\n",
       "x18            0.0275      0.022      1.256      0.209      -0.015       0.070\n",
       "x19            0.0434      0.015      2.935      0.003       0.014       0.072\n",
       "x20            0.0098      0.014      0.694      0.488      -0.018       0.037\n",
       "x21           -0.0082      0.009     -0.909      0.363      -0.026       0.009\n",
       "x22           -0.0738      0.029     -2.549      0.011      -0.131      -0.017\n",
       "x23            0.0208      0.006      3.206      0.001       0.008       0.033\n",
       "x24            0.0393      0.009      4.307      0.000       0.021       0.057\n",
       "x25           -0.0001      0.000     -0.373      0.710      -0.001       0.001\n",
       "x26            0.0772      0.014      5.332      0.000       0.049       0.106\n",
       "x27        -2.579e-05   5.06e-05     -0.510      0.610      -0.000    7.35e-05\n",
       "x28            0.0002   4.14e-05      4.311      0.000    9.73e-05       0.000\n",
       "x29         9.499e-05   7.93e-05      1.197      0.231   -6.07e-05       0.000\n",
       "x30            0.0002   8.62e-05      2.067      0.039       9e-06       0.000\n",
       "x31            0.0003      0.000      1.941      0.053   -3.21e-06       0.001\n",
       "x32            0.0004   9.63e-05      3.767      0.000       0.000       0.001\n",
       "x33           -0.0004      0.000     -2.784      0.005      -0.001      -0.000\n",
       "x34         -1.58e-06   8.13e-06     -0.194      0.846   -1.75e-05    1.44e-05\n",
       "x35            0.0020      0.002      1.146      0.252      -0.001       0.005\n",
       "x36           -0.0076      0.004     -2.054      0.040      -0.015      -0.000\n",
       "==============================================================================\n",
       "Omnibus:                      712.487   Durbin-Watson:                   1.933\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            30101.499\n",
       "Skew:                          -2.650   Prob(JB):                         0.00\n",
       "Kurtosis:                      29.054   Cond. No.                     1.37e+16\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 1.38e-21. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#     (v) Compare your results (i), (ii), (iii) (with and without pseudoinversion) to the output of the sm.OLS function. \n",
    "ols_model = sm.OLS(y_train_mat, sm.add_constant(X_train_mat, prepend=True))\n",
    "ols_res = ols_model.fit()\n",
    "ols_res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c386168d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beta_hat</th>\n",
       "      <th>se</th>\n",
       "      <th>t_stat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Intercept</th>\n",
       "      <td>18.140570</td>\n",
       "      <td>7.411651e+00</td>\n",
       "      <td>2.447575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSSubClass</th>\n",
       "      <td>-0.000733</td>\n",
       "      <td>1.428910e-04</td>\n",
       "      <td>-5.126727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotFrontage</th>\n",
       "      <td>-0.000273</td>\n",
       "      <td>2.624315e-04</td>\n",
       "      <td>-1.039735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotArea</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>4.654390e-07</td>\n",
       "      <td>3.885164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OverallQual</th>\n",
       "      <td>0.087042</td>\n",
       "      <td>6.222362e-03</td>\n",
       "      <td>13.988621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OverallCond</th>\n",
       "      <td>0.048559</td>\n",
       "      <td>5.330693e-03</td>\n",
       "      <td>9.109365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YearBuilt</th>\n",
       "      <td>0.003062</td>\n",
       "      <td>3.415510e-04</td>\n",
       "      <td>8.964807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <td>0.000961</td>\n",
       "      <td>3.546719e-04</td>\n",
       "      <td>2.710434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MasVnrArea</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>2.967949e-05</td>\n",
       "      <td>0.114158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <td>0.000018</td>\n",
       "      <td>1.327556e-05</td>\n",
       "      <td>1.389237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>2.487573e-05</td>\n",
       "      <td>0.084467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.285508e-05</td>\n",
       "      <td>0.103070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <td>0.000022</td>\n",
       "      <td>1.799715e-05</td>\n",
       "      <td>1.215140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1stFlrSF</th>\n",
       "      <td>0.000056</td>\n",
       "      <td>3.062894e-05</td>\n",
       "      <td>1.833414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <td>0.000029</td>\n",
       "      <td>2.847386e-05</td>\n",
       "      <td>1.011448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LowQualFinSF</th>\n",
       "      <td>0.000051</td>\n",
       "      <td>7.155895e-05</td>\n",
       "      <td>0.709753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GrLivArea</th>\n",
       "      <td>0.000136</td>\n",
       "      <td>2.751641e-05</td>\n",
       "      <td>4.933222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <td>0.067200</td>\n",
       "      <td>1.368705e-02</td>\n",
       "      <td>4.909777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <td>0.027456</td>\n",
       "      <td>2.186204e-02</td>\n",
       "      <td>1.255891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FullBath</th>\n",
       "      <td>0.043413</td>\n",
       "      <td>1.479136e-02</td>\n",
       "      <td>2.935042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HalfBath</th>\n",
       "      <td>0.009781</td>\n",
       "      <td>1.408909e-02</td>\n",
       "      <td>0.694207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <td>-0.008155</td>\n",
       "      <td>8.969108e-03</td>\n",
       "      <td>-0.909250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <td>-0.073766</td>\n",
       "      <td>2.893660e-02</td>\n",
       "      <td>-2.549211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <td>0.020769</td>\n",
       "      <td>6.477506e-03</td>\n",
       "      <td>3.206271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fireplaces</th>\n",
       "      <td>0.039261</td>\n",
       "      <td>9.115417e-03</td>\n",
       "      <td>4.307122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <td>-0.000133</td>\n",
       "      <td>3.582826e-04</td>\n",
       "      <td>-0.372583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageCars</th>\n",
       "      <td>0.077228</td>\n",
       "      <td>1.448389e-02</td>\n",
       "      <td>5.332005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageArea</th>\n",
       "      <td>-0.000026</td>\n",
       "      <td>5.059433e-05</td>\n",
       "      <td>-0.509755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <td>0.000179</td>\n",
       "      <td>4.141559e-05</td>\n",
       "      <td>4.311049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <td>0.000095</td>\n",
       "      <td>7.933995e-05</td>\n",
       "      <td>1.197242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <td>0.000178</td>\n",
       "      <td>8.621062e-05</td>\n",
       "      <td>2.066814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3SsnPorch</th>\n",
       "      <td>0.000286</td>\n",
       "      <td>1.476310e-04</td>\n",
       "      <td>1.940605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ScreenPorch</th>\n",
       "      <td>0.000363</td>\n",
       "      <td>9.625238e-05</td>\n",
       "      <td>3.767072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PoolArea</th>\n",
       "      <td>-0.000351</td>\n",
       "      <td>1.262245e-04</td>\n",
       "      <td>-2.784241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MiscVal</th>\n",
       "      <td>-0.000002</td>\n",
       "      <td>8.132973e-06</td>\n",
       "      <td>-0.194305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MoSold</th>\n",
       "      <td>0.002024</td>\n",
       "      <td>1.766720e-03</td>\n",
       "      <td>1.145889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YrSold</th>\n",
       "      <td>-0.007569</td>\n",
       "      <td>3.685855e-03</td>\n",
       "      <td>-2.053659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                beta_hat            se     t_stat\n",
       "Intercept      18.140570  7.411651e+00   2.447575\n",
       "MSSubClass     -0.000733  1.428910e-04  -5.126727\n",
       "LotFrontage    -0.000273  2.624315e-04  -1.039735\n",
       "LotArea         0.000002  4.654390e-07   3.885164\n",
       "OverallQual     0.087042  6.222362e-03  13.988621\n",
       "OverallCond     0.048559  5.330693e-03   9.109365\n",
       "YearBuilt       0.003062  3.415510e-04   8.964807\n",
       "YearRemodAdd    0.000961  3.546719e-04   2.710434\n",
       "MasVnrArea      0.000003  2.967949e-05   0.114158\n",
       "BsmtFinSF1      0.000018  1.327556e-05   1.389237\n",
       "BsmtFinSF2      0.000002  2.487573e-05   0.084467\n",
       "BsmtUnfSF       0.000001  1.285508e-05   0.103070\n",
       "TotalBsmtSF     0.000022  1.799715e-05   1.215140\n",
       "1stFlrSF        0.000056  3.062894e-05   1.833414\n",
       "2ndFlrSF        0.000029  2.847386e-05   1.011448\n",
       "LowQualFinSF    0.000051  7.155895e-05   0.709753\n",
       "GrLivArea       0.000136  2.751641e-05   4.933222\n",
       "BsmtFullBath    0.067200  1.368705e-02   4.909777\n",
       "BsmtHalfBath    0.027456  2.186204e-02   1.255891\n",
       "FullBath        0.043413  1.479136e-02   2.935042\n",
       "HalfBath        0.009781  1.408909e-02   0.694207\n",
       "BedroomAbvGr   -0.008155  8.969108e-03  -0.909250\n",
       "KitchenAbvGr   -0.073766  2.893660e-02  -2.549211\n",
       "TotRmsAbvGrd    0.020769  6.477506e-03   3.206271\n",
       "Fireplaces      0.039261  9.115417e-03   4.307122\n",
       "GarageYrBlt    -0.000133  3.582826e-04  -0.372583\n",
       "GarageCars      0.077228  1.448389e-02   5.332005\n",
       "GarageArea     -0.000026  5.059433e-05  -0.509755\n",
       "WoodDeckSF      0.000179  4.141559e-05   4.311049\n",
       "OpenPorchSF     0.000095  7.933995e-05   1.197242\n",
       "EnclosedPorch   0.000178  8.621062e-05   2.066814\n",
       "3SsnPorch       0.000286  1.476310e-04   1.940605\n",
       "ScreenPorch     0.000363  9.625238e-05   3.767072\n",
       "PoolArea       -0.000351  1.262245e-04  -2.784241\n",
       "MiscVal        -0.000002  8.132973e-06  -0.194305\n",
       "MoSold          0.002024  1.766720e-03   1.145889\n",
       "YrSold         -0.007569  3.685855e-03  -2.053659"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ols_res_df = pd.DataFrame(\n",
    "    {\n",
    "        \"beta_hat\": ols_res.params,\n",
    "        \"se\": ols_res.bse,\n",
    "        \"t_stat\": ols_res.tvalues,\n",
    "    },\n",
    "    index=feature_names,\n",
    ")\n",
    "ols_res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1611da4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(est_pinv.values[:, 0], ols_res_df.values[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9e56196b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(est_pinv.values[:, 1], ols_res_df.values[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699c9ae8",
   "metadata": {},
   "source": [
    "<span style=\"color: blue;\"><strong>Discussion:</strong></span>\n",
    "1. We see the beta estimates by pseudo-inverse are agreed by sm.OLS\n",
    "1. But there are small discrepancies in SE. The reason is sm.OLS eliminates the colinearity first, thus resulting in fewer features, thus smaller SEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a1114545-6d94-4276-9e6a-cc84a49309bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.d) Suggest instead a second-order polynomial regression model (including all quadratic and mixed terms) to predict the (transformed) SalePrice.\n",
    "\n",
    "#Does this improve the linear regression model 2.b)? \n",
    "\n",
    "#What happens with higher-order polynomial regression models?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684ff95c",
   "metadata": {},
   "source": [
    "<span style=\"color: blue;\"><strong>Sanity check on polynomial features:</strong></span>\n",
    "- Bias\n",
    "- $x_i^2 \\quad \\forall i \\in [d]$\n",
    "- $x_i \\cdot x_j \\quad \\forall i, j \\in [d],\\ i \\neq j$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "11a0be48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['1', 'x0', 'x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8',\n",
       "       ...\n",
       "       'x32^2', 'x32 x33', 'x32 x34', 'x32 x35', 'x33^2', 'x33 x34', 'x33 x35',\n",
       "       'x34^2', 'x34 x35', 'x35^2'],\n",
       "      dtype='object', length=703)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfm = create_pipeline(PolynomialFeatures(degree=2))\n",
    "X_train_tfm_temp = tfm.fit_transform(X_train_numerical)\n",
    "X_train_tfm_temp_df = pd.DataFrame(X_train_tfm_temp, columns=tfm[\"model\"].get_feature_names_out())\n",
    "X_train_tfm_temp_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cfe5798c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;numerical_imputer&#x27;,\n",
       "                                                  SimpleImputer(),\n",
       "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000151489294F0&gt;),\n",
       "                                                 (&#x27;categorical_tfm&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;na_imputer&#x27;,\n",
       "                                                                   SimpleImputer(fill_value=&#x27;NA&#x27;,\n",
       "                                                                                 strategy=&#x27;constant&#x27;)),\n",
       "                                                                  (&#x27;one_hot_encoder&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x0000015148929A30&gt;)])),\n",
       "                (&#x27;model&#x27;,\n",
       "                 Pipeline(steps=[(&#x27;poly_feat&#x27;, PolynomialFeatures()),\n",
       "                                 (&#x27;model&#x27;,\n",
       "                                  LinearRegression(fit_intercept=False))]))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;numerical_imputer&#x27;,\n",
       "                                                  SimpleImputer(),\n",
       "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000151489294F0&gt;),\n",
       "                                                 (&#x27;categorical_tfm&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;na_imputer&#x27;,\n",
       "                                                                   SimpleImputer(fill_value=&#x27;NA&#x27;,\n",
       "                                                                                 strategy=&#x27;constant&#x27;)),\n",
       "                                                                  (&#x27;one_hot_encoder&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x0000015148929A30&gt;)])),\n",
       "                (&#x27;model&#x27;,\n",
       "                 Pipeline(steps=[(&#x27;poly_feat&#x27;, PolynomialFeatures()),\n",
       "                                 (&#x27;model&#x27;,\n",
       "                                  LinearRegression(fit_intercept=False))]))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;preprocessor: ColumnTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for preprocessor: ColumnTransformer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(transformers=[(&#x27;numerical_imputer&#x27;, SimpleImputer(),\n",
       "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000151489294F0&gt;),\n",
       "                                (&#x27;categorical_tfm&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;na_imputer&#x27;,\n",
       "                                                  SimpleImputer(fill_value=&#x27;NA&#x27;,\n",
       "                                                                strategy=&#x27;constant&#x27;)),\n",
       "                                                 (&#x27;one_hot_encoder&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x0000015148929A30&gt;)])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">numerical_imputer</label><div class=\"sk-toggleable__content fitted\"><pre>&lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000151489294F0&gt;</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;SimpleImputer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.impute.SimpleImputer.html\">?<span>Documentation for SimpleImputer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>SimpleImputer()</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">categorical_tfm</label><div class=\"sk-toggleable__content fitted\"><pre>&lt;sklearn.compose._column_transformer.make_column_selector object at 0x0000015148929A30&gt;</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;SimpleImputer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.impute.SimpleImputer.html\">?<span>Documentation for SimpleImputer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>SimpleImputer(fill_value=&#x27;NA&#x27;, strategy=&#x27;constant&#x27;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;OneHotEncoder<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div> </div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;model: Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for model: Pipeline</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;poly_feat&#x27;, PolynomialFeatures()),\n",
       "                (&#x27;model&#x27;, LinearRegression(fit_intercept=False))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;PolynomialFeatures<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.PolynomialFeatures.html\">?<span>Documentation for PolynomialFeatures</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>PolynomialFeatures()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LinearRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression(fit_intercept=False)</pre></div> </div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('numerical_imputer',\n",
       "                                                  SimpleImputer(),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x00000151489294F0>),\n",
       "                                                 ('categorical_tfm',\n",
       "                                                  Pipeline(steps=[('na_imputer',\n",
       "                                                                   SimpleImputer(fill_value='NA',\n",
       "                                                                                 strategy='constant')),\n",
       "                                                                  ('one_hot_encoder',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x0000015148929A30>)])),\n",
       "                ('model',\n",
       "                 Pipeline(steps=[('poly_feat', PolynomialFeatures()),\n",
       "                                 ('model',\n",
       "                                  LinearRegression(fit_intercept=False))]))])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit a LR model with all features\n",
    "model = Pipeline([\n",
    "    (\"poly_feat\", PolynomialFeatures(degree=2)),\n",
    "    (\"model\", LinearRegression(fit_intercept=False)),  # Already added bias term using PolynomialFeatures()\n",
    "])\n",
    "pipeline = create_pipeline(model)\n",
    "pipeline.fit(X_train_numerical, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "43d0af29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>r2_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>in-sample</th>\n",
       "      <td>0.005140</td>\n",
       "      <td>0.967077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out-of-sample</th>\n",
       "      <td>11146.724647</td>\n",
       "      <td>-66791.852472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               mean_squared_error      r2_score\n",
       "in-sample                0.005140      0.967077\n",
       "out-of-sample        11146.724647 -66791.852472"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_poly_df = compute_metrics(\n",
    "    [mean_squared_error, r2_score],\n",
    "    pipeline,\n",
    "    X_train_numerical,\n",
    "    y_train,\n",
    "    X_test_numerical,\n",
    "    y_test\n",
    ")\n",
    "metrics_poly_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9385514f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>r2_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>in-sample</th>\n",
       "      <td>0.021603</td>\n",
       "      <td>0.861617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out-of-sample</th>\n",
       "      <td>0.020817</td>\n",
       "      <td>0.875258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               mean_squared_error  r2_score\n",
       "in-sample                0.021603  0.861617\n",
       "out-of-sample            0.020817  0.875258"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare with LR\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16080c91",
   "metadata": {},
   "source": [
    "<span style=\"color: blue;\"><strong>Discussion:</strong></span>\n",
    "\n",
    "1. The polynomial features result in heavy overfitting. We can see out-of-sample MSE is much bigger than in-sample, and out-of-sample $R^2$ is highly negative. This result should eliminate the use of even higher polynomial features.\n",
    "1. Since polynomial features underperform the original features in out-of-sample dataset severely, there's no improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31c5ecc-7f64-4788-9237-76dff4e3fb3e",
   "metadata": {},
   "source": [
    "### Question 3 - Regularization techniques on Housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ff8ff75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.model_selection import cross_val_score, RepeatedKFold, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5bd0add2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1022, 79), (1022,), (438, 79), (438,))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure the same indices\n",
    "train_inds = X_train_numerical.index\n",
    "test_inds = X_test_numerical.index\n",
    "X_train, y_train = X_all.loc[train_inds], y_all.loc[train_inds]\n",
    "X_test, y_test = X_all.loc[test_inds], y_all.loc[test_inds]\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "505e55f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>r2_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>in-sample</th>\n",
       "      <td>0.011887</td>\n",
       "      <td>0.923856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out-of-sample</th>\n",
       "      <td>0.017565</td>\n",
       "      <td>0.894748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               mean_squared_error  r2_score\n",
       "in-sample                0.011887  0.923856\n",
       "out-of-sample            0.017565  0.894748"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3.a) Perform again a linear regression for the (transformed) SalePrice using this time the full Housing DataFrame. \n",
    "\n",
    "#How do the in-sample and out-of-sample MSE and R^2 metrics compare to the results of Question 2.b) on the Housing2 DataFrame?\n",
    "pipeline = create_pipeline(LinearRegression())\n",
    "pipeline.fit(X_train, y_train)\n",
    "metrics_lr_df = compute_metrics(\n",
    "    [mean_squared_error, r2_score],\n",
    "    pipeline,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    ")\n",
    "metrics_lr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bf3a1831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>r2_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>in-sample</th>\n",
       "      <td>0.021603</td>\n",
       "      <td>0.861617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out-of-sample</th>\n",
       "      <td>0.020817</td>\n",
       "      <td>0.875258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               mean_squared_error  r2_score\n",
       "in-sample                0.021603  0.861617\n",
       "out-of-sample            0.020817  0.875258"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare with LR with only numerical features\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36862e3",
   "metadata": {},
   "source": [
    "<span style=\"color: blue;\"><strong>Discussion:</strong></span>\n",
    "\n",
    "Using all features improves the model performance both for training and test samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5abb5f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.b)  Implement the truncated pseudoinverse, Ridge and Lasso regularization techniques. \n",
    "#Use 8-fold cross-validation to tune the hyperparameters of each regularization technique based on the MSE metric.\n",
    "\n",
    "#Compare their performance in terms of in-sample and out-of-sample MSE with the linear regressions of Questions 2.b) and 3.a).\n",
    "def hyperparam_tuning(model: BaseEstimator, param_distr: dict, X_train, y_train, **kwargs):\n",
    "    \"\"\"\n",
    "    Using Optuna for fast hyperparameter tuning.\n",
    "    \"\"\"\n",
    "    optuna_search = OptunaSearchCV(\n",
    "        estimator=model,\n",
    "        param_distributions=param_distr,\n",
    "        **kwargs,\n",
    "    )\n",
    "    optuna_search.fit(X_train, y_train)\n",
    "    \n",
    "    return optuna_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a213e613",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPTUNA_SEARCH_CONFIG = {\n",
    "    \"cv\": 8,\n",
    "    \"n_trials\": 50,\n",
    "    \"random_state\": SEED,\n",
    "    \"n_jobs\": -1,\n",
    "    \"scoring\": \"neg_mean_squared_error\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79376edd",
   "metadata": {},
   "source": [
    "### Truncated Pseudo-Inverse\n",
    "\n",
    "Truncated pseudo-inverse is equivalent as performing truncated SVD on the features and then performing linear regression.\n",
    "\n",
    "We first inspect the distribution of the design matrix's singular values. Note we use the full dataset for the inspection, but for model training we use the training set or cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9d8f36fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of all features after transform: (1460, 304)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Value')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1296x691.2 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"Shape of all features after transform: {X_all_tfm_df.shape}\")\n",
    "U, S, Vh = np.linalg.svd(X_all_tfm_df)\n",
    "fig, axis = plt.subplots(figsize=(18, 9.6))\n",
    "axis.scatter(np.arange(S.shape[0]) + 1, S)\n",
    "axis.set_yscale(\"log\")\n",
    "font_dict = {\n",
    "    \"fontsize\": 18,\n",
    "}\n",
    "axis.set_title(\"Singular Values of the Design Matrix\", fontdict=font_dict)\n",
    "axis.set_xlabel(\"Rank\", fontdict=font_dict)\n",
    "axis.set_ylabel(\"Value\", fontdict=font_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d57ed31",
   "metadata": {},
   "source": [
    "From the plot above, we can choose the maximum number of singular values kept is around 260, and we should keep the large ones i.e. up to approximate the 30th singular value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d4841e9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;numerical_imputer&#x27;,\n",
       "                                                  SimpleImputer(),\n",
       "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001514A352F10&gt;),\n",
       "                                                 (&#x27;categorical_tfm&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;na_imputer&#x27;,\n",
       "                                                                   SimpleImputer(fill_value=&#x27;NA&#x27;,\n",
       "                                                                                 strategy=&#x27;constant&#x27;)),\n",
       "                                                                  (&#x27;one_hot_encoder&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001514A3BB640&gt;)])),\n",
       "                (&#x27;model&#x27;,\n",
       "                 Pipeline(steps=[(&#x27;truncated_svd&#x27;,\n",
       "                                  TruncatedSVD(algorithm=&#x27;arpack&#x27;)),\n",
       "                                 (&#x27;estimator&#x27;, LinearRegression())]))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link \">i<span>Not fitted</span></span></label><div class=\"sk-toggleable__content \"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;numerical_imputer&#x27;,\n",
       "                                                  SimpleImputer(),\n",
       "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001514A352F10&gt;),\n",
       "                                                 (&#x27;categorical_tfm&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;na_imputer&#x27;,\n",
       "                                                                   SimpleImputer(fill_value=&#x27;NA&#x27;,\n",
       "                                                                                 strategy=&#x27;constant&#x27;)),\n",
       "                                                                  (&#x27;one_hot_encoder&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001514A3BB640&gt;)])),\n",
       "                (&#x27;model&#x27;,\n",
       "                 Pipeline(steps=[(&#x27;truncated_svd&#x27;,\n",
       "                                  TruncatedSVD(algorithm=&#x27;arpack&#x27;)),\n",
       "                                 (&#x27;estimator&#x27;, LinearRegression())]))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;preprocessor: ColumnTransformer<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for preprocessor: ColumnTransformer</span></a></label><div class=\"sk-toggleable__content \"><pre>ColumnTransformer(transformers=[(&#x27;numerical_imputer&#x27;, SimpleImputer(),\n",
       "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001514A352F10&gt;),\n",
       "                                (&#x27;categorical_tfm&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;na_imputer&#x27;,\n",
       "                                                  SimpleImputer(fill_value=&#x27;NA&#x27;,\n",
       "                                                                strategy=&#x27;constant&#x27;)),\n",
       "                                                 (&#x27;one_hot_encoder&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001514A3BB640&gt;)])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">numerical_imputer</label><div class=\"sk-toggleable__content \"><pre>&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001514A352F10&gt;</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;SimpleImputer<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.impute.SimpleImputer.html\">?<span>Documentation for SimpleImputer</span></a></label><div class=\"sk-toggleable__content \"><pre>SimpleImputer()</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">categorical_tfm</label><div class=\"sk-toggleable__content \"><pre>&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001514A3BB640&gt;</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;SimpleImputer<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.impute.SimpleImputer.html\">?<span>Documentation for SimpleImputer</span></a></label><div class=\"sk-toggleable__content \"><pre>SimpleImputer(fill_value=&#x27;NA&#x27;, strategy=&#x27;constant&#x27;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;OneHotEncoder<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></label><div class=\"sk-toggleable__content \"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div> </div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;model: Pipeline<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for model: Pipeline</span></a></label><div class=\"sk-toggleable__content \"><pre>Pipeline(steps=[(&#x27;truncated_svd&#x27;, TruncatedSVD(algorithm=&#x27;arpack&#x27;)),\n",
       "                (&#x27;estimator&#x27;, LinearRegression())])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;TruncatedSVD<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.decomposition.TruncatedSVD.html\">?<span>Documentation for TruncatedSVD</span></a></label><div class=\"sk-toggleable__content \"><pre>TruncatedSVD(algorithm=&#x27;arpack&#x27;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;LinearRegression<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a></label><div class=\"sk-toggleable__content \"><pre>LinearRegression()</pre></div> </div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('numerical_imputer',\n",
       "                                                  SimpleImputer(),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x000001514A352F10>),\n",
       "                                                 ('categorical_tfm',\n",
       "                                                  Pipeline(steps=[('na_imputer',\n",
       "                                                                   SimpleImputer(fill_value='NA',\n",
       "                                                                                 strategy='constant')),\n",
       "                                                                  ('one_hot_encoder',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x000001514A3BB640>)])),\n",
       "                ('model',\n",
       "                 Pipeline(steps=[('truncated_svd',\n",
       "                                  TruncatedSVD(algorithm='arpack')),\n",
       "                                 ('estimator', LinearRegression())]))])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Pipeline([\n",
    "    (\"truncated_svd\", TruncatedSVD(algorithm=\"arpack\")),\n",
    "    (\"estimator\", LinearRegression()),\n",
    "])\n",
    "pipeline = create_pipeline(model)\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3743068f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_3484\\2729002508.py:9: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.\n",
      "  optuna_search = OptunaSearchCV(\n",
      "[I 2024-09-27 17:39:08,349] A new study created in memory with name: no-name-20148c79-fd24-4d2b-873d-2dae34af1d77\n",
      "[I 2024-09-27 17:40:10,214] Trial 0 finished with value: -0.024884586583069856 and parameters: {'model__truncated_svd__n_components': 106}. Best is trial 0 with value: -0.024884586583069856.\n",
      "[I 2024-09-27 17:40:10,887] Trial 5 finished with value: -0.025894170697697266 and parameters: {'model__truncated_svd__n_components': 136}. Best is trial 0 with value: -0.024884586583069856.\n",
      "[I 2024-09-27 17:40:11,854] Trial 2 finished with value: -0.029986839225595342 and parameters: {'model__truncated_svd__n_components': 217}. Best is trial 0 with value: -0.024884586583069856.\n",
      "[I 2024-09-27 17:40:12,535] Trial 9 finished with value: -0.025941364185325846 and parameters: {'model__truncated_svd__n_components': 139}. Best is trial 0 with value: -0.024884586583069856.\n",
      "[I 2024-09-27 17:40:13,439] Trial 1 finished with value: -0.02816733598723842 and parameters: {'model__truncated_svd__n_components': 189}. Best is trial 0 with value: -0.024884586583069856.\n",
      "[I 2024-09-27 17:40:14,374] Trial 8 finished with value: -0.03333749668612079 and parameters: {'model__truncated_svd__n_components': 227}. Best is trial 0 with value: -0.024884586583069856.\n",
      "[I 2024-09-27 17:40:14,639] Trial 7 finished with value: -0.026858505620119398 and parameters: {'model__truncated_svd__n_components': 73}. Best is trial 0 with value: -0.024884586583069856.\n",
      "[I 2024-09-27 17:40:14,800] Trial 4 finished with value: -0.02949643089860234 and parameters: {'model__truncated_svd__n_components': 42}. Best is trial 0 with value: -0.024884586583069856.\n",
      "[I 2024-09-27 17:40:14,988] Trial 14 finished with value: -0.029611041090232253 and parameters: {'model__truncated_svd__n_components': 45}. Best is trial 0 with value: -0.024884586583069856.\n",
      "[I 2024-09-27 17:40:15,242] Trial 11 finished with value: -0.029060607128166098 and parameters: {'model__truncated_svd__n_components': 55}. Best is trial 0 with value: -0.024884586583069856.\n",
      "[I 2024-09-27 17:40:15,569] Trial 6 finished with value: -0.02625455492531307 and parameters: {'model__truncated_svd__n_components': 77}. Best is trial 0 with value: -0.024884586583069856.\n",
      "[I 2024-09-27 17:40:16,462] Trial 13 finished with value: -0.026988609783734498 and parameters: {'model__truncated_svd__n_components': 178}. Best is trial 0 with value: -0.024884586583069856.\n",
      "[I 2024-09-27 17:40:17,170] Trial 12 finished with value: -0.02604745485511953 and parameters: {'model__truncated_svd__n_components': 140}. Best is trial 0 with value: -0.024884586583069856.\n",
      "[I 2024-09-27 17:40:17,407] Trial 10 finished with value: -0.02832605807101587 and parameters: {'model__truncated_svd__n_components': 57}. Best is trial 0 with value: -0.024884586583069856.\n",
      "[I 2024-09-27 17:40:17,780] Trial 15 finished with value: -0.025932917011692695 and parameters: {'model__truncated_svd__n_components': 85}. Best is trial 0 with value: -0.024884586583069856.\n",
      "[I 2024-09-27 17:40:18,484] Trial 3 finished with value: -0.025782930739251142 and parameters: {'model__truncated_svd__n_components': 128}. Best is trial 0 with value: -0.024884586583069856.\n",
      "[I 2024-09-27 17:41:24,429] Trial 16 finished with value: -0.025811570777839358 and parameters: {'model__truncated_svd__n_components': 157}. Best is trial 0 with value: -0.024884586583069856.\n",
      "[I 2024-09-27 17:41:24,671] Trial 17 finished with value: -0.02745476962278858 and parameters: {'model__truncated_svd__n_components': 70}. Best is trial 0 with value: -0.024884586583069856.\n",
      "[I 2024-09-27 17:41:25,493] Trial 18 finished with value: -0.026218970445541726 and parameters: {'model__truncated_svd__n_components': 155}. Best is trial 0 with value: -0.024884586583069856.\n",
      "[I 2024-09-27 17:41:25,980] Trial 19 finished with value: -0.025047342034814138 and parameters: {'model__truncated_svd__n_components': 107}. Best is trial 0 with value: -0.024884586583069856.\n",
      "[I 2024-09-27 17:41:26,981] Trial 20 finished with value: -0.032077173102673336 and parameters: {'model__truncated_svd__n_components': 223}. Best is trial 0 with value: -0.024884586583069856.\n",
      "[I 2024-09-27 17:41:27,740] Trial 21 finished with value: -0.02640276216081027 and parameters: {'model__truncated_svd__n_components': 165}. Best is trial 0 with value: -0.024884586583069856.\n",
      "[I 2024-09-27 17:41:28,054] Trial 22 finished with value: -0.026269188084674128 and parameters: {'model__truncated_svd__n_components': 80}. Best is trial 0 with value: -0.024884586583069856.\n",
      "[I 2024-09-27 17:41:29,024] Trial 23 finished with value: -0.02942376694639657 and parameters: {'model__truncated_svd__n_components': 214}. Best is trial 0 with value: -0.024884586583069856.\n",
      "[I 2024-09-27 17:41:29,180] Trial 24 finished with value: -0.029741591759331006 and parameters: {'model__truncated_svd__n_components': 46}. Best is trial 0 with value: -0.024884586583069856.\n",
      "[I 2024-09-27 17:41:29,756] Trial 25 finished with value: -0.025220516463523468 and parameters: {'model__truncated_svd__n_components': 109}. Best is trial 0 with value: -0.024884586583069856.\n",
      "[I 2024-09-27 17:41:30,423] Trial 26 finished with value: -0.025756778000910578 and parameters: {'model__truncated_svd__n_components': 127}. Best is trial 0 with value: -0.024884586583069856.\n",
      "[I 2024-09-27 17:41:31,015] Trial 27 finished with value: -0.02577231557163388 and parameters: {'model__truncated_svd__n_components': 119}. Best is trial 0 with value: -0.024884586583069856.\n",
      "[I 2024-09-27 17:41:31,591] Trial 28 finished with value: -0.02592674881080769 and parameters: {'model__truncated_svd__n_components': 117}. Best is trial 0 with value: -0.024884586583069856.\n",
      "[I 2024-09-27 17:41:32,048] Trial 29 finished with value: -0.024661363003926403 and parameters: {'model__truncated_svd__n_components': 101}. Best is trial 29 with value: -0.024661363003926403.\n",
      "[I 2024-09-27 17:41:32,563] Trial 30 finished with value: -0.025047341916796657 and parameters: {'model__truncated_svd__n_components': 107}. Best is trial 29 with value: -0.024661363003926403.\n",
      "[I 2024-09-27 17:41:33,075] Trial 31 finished with value: -0.025086028522309352 and parameters: {'model__truncated_svd__n_components': 108}. Best is trial 29 with value: -0.024661363003926403.\n",
      "[I 2024-09-27 17:42:27,643] Trial 32 finished with value: -0.02522051647918799 and parameters: {'model__truncated_svd__n_components': 109}. Best is trial 29 with value: -0.024661363003926403.\n",
      "[I 2024-09-27 17:42:28,159] Trial 33 finished with value: -0.02508602847760628 and parameters: {'model__truncated_svd__n_components': 108}. Best is trial 29 with value: -0.024661363003926403.\n",
      "[I 2024-09-27 17:42:28,686] Trial 34 finished with value: -0.025220516502887605 and parameters: {'model__truncated_svd__n_components': 109}. Best is trial 29 with value: -0.024661363003926403.\n",
      "[I 2024-09-27 17:42:29,124] Trial 35 finished with value: -0.024646674904511844 and parameters: {'model__truncated_svd__n_components': 102}. Best is trial 35 with value: -0.024646674904511844.\n",
      "[I 2024-09-27 17:42:29,672] Trial 36 finished with value: -0.025006532596467408 and parameters: {'model__truncated_svd__n_components': 110}. Best is trial 35 with value: -0.024646674904511844.\n",
      "[I 2024-09-27 17:42:30,229] Trial 37 finished with value: -0.025329487779206787 and parameters: {'model__truncated_svd__n_components': 111}. Best is trial 35 with value: -0.024646674904511844.\n",
      "[I 2024-09-27 17:42:30,731] Trial 38 finished with value: -0.025220516398267074 and parameters: {'model__truncated_svd__n_components': 109}. Best is trial 35 with value: -0.024646674904511844.\n",
      "[I 2024-09-27 17:42:31,181] Trial 39 finished with value: -0.024653612663148937 and parameters: {'model__truncated_svd__n_components': 103}. Best is trial 35 with value: -0.024646674904511844.\n",
      "[I 2024-09-27 17:42:31,692] Trial 40 finished with value: -0.025006532671971175 and parameters: {'model__truncated_svd__n_components': 110}. Best is trial 35 with value: -0.024646674904511844.\n",
      "[I 2024-09-27 17:42:32,185] Trial 41 finished with value: -0.025047342026620695 and parameters: {'model__truncated_svd__n_components': 107}. Best is trial 35 with value: -0.024646674904511844.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-27 17:42:32,665] Trial 42 finished with value: -0.024884586545410006 and parameters: {'model__truncated_svd__n_components': 106}. Best is trial 35 with value: -0.024646674904511844.\n",
      "[I 2024-09-27 17:42:33,136] Trial 43 finished with value: -0.024653612711036936 and parameters: {'model__truncated_svd__n_components': 103}. Best is trial 35 with value: -0.024646674904511844.\n",
      "[I 2024-09-27 17:42:33,558] Trial 44 finished with value: -0.02432857674441747 and parameters: {'model__truncated_svd__n_components': 99}. Best is trial 44 with value: -0.02432857674441747.\n",
      "[I 2024-09-27 17:42:33,983] Trial 45 finished with value: -0.024485311084009885 and parameters: {'model__truncated_svd__n_components': 100}. Best is trial 44 with value: -0.02432857674441747.\n",
      "[I 2024-09-27 17:42:34,415] Trial 46 finished with value: -0.024661362989129014 and parameters: {'model__truncated_svd__n_components': 101}. Best is trial 44 with value: -0.02432857674441747.\n",
      "[I 2024-09-27 17:42:34,814] Trial 47 finished with value: -0.024138627019104075 and parameters: {'model__truncated_svd__n_components': 97}. Best is trial 47 with value: -0.024138627019104075.\n",
      "[I 2024-09-27 17:42:40,579] Trial 48 finished with value: -0.02531951334364667 and parameters: {'model__truncated_svd__n_components': 91}. Best is trial 47 with value: -0.024138627019104075.\n",
      "[I 2024-09-27 17:42:40,954] Trial 49 finished with value: -0.025990749445993326 and parameters: {'model__truncated_svd__n_components': 89}. Best is trial 47 with value: -0.024138627019104075.\n"
     ]
    }
   ],
   "source": [
    "param_distr = {\n",
    "    \"model__truncated_svd__n_components\": opt_distr.IntDistribution(30, 260),\n",
    "}\n",
    "optuna_search_truncated_pinv = hyperparam_tuning(\n",
    "    pipeline, \n",
    "    param_distr,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    **OPTUNA_SEARCH_CONFIG,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "41e60719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best params are {'model__truncated_svd__n_components': 97}\n",
      "The best avg MSE from CV is 0.02414\n"
     ]
    }
   ],
   "source": [
    "print(f\"The best params are {optuna_search_truncated_pinv.best_params_}\")\n",
    "print(f\"The best avg MSE from CV is {-optuna_search_truncated_pinv.best_score_:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "75f13021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"dev/truncated_pinv_optuna_CV.pkl\", \"wb\") as wf:\n",
    "#     pickle.dump(optuna_search_truncated_pinv, wf)\n",
    "\n",
    "# with open(\"dev/truncated_pinv_optuna_CV.pkl\", \"rb\") as rf:\n",
    "#     optuna_search_truncated_pinv = pickle.load(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f8fdd200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>r2_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>in-sample</th>\n",
       "      <td>0.015699</td>\n",
       "      <td>0.899435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out-of-sample</th>\n",
       "      <td>0.019424</td>\n",
       "      <td>0.883607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               mean_squared_error  r2_score\n",
       "in-sample                0.015699  0.899435\n",
       "out-of-sample            0.019424  0.883607"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_truncated_pinv_df = compute_metrics(\n",
    "    [mean_squared_error, r2_score],\n",
    "    optuna_search_truncated_pinv.best_estimator_,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    ")\n",
    "metrics_truncated_pinv_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88f333a",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b30d110c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_3484\\2729002508.py:9: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.\n",
      "  optuna_search = OptunaSearchCV(\n",
      "[I 2024-09-27 17:42:41,552] A new study created in memory with name: no-name-90f7b561-4bf2-40d5-bef2-adf856484e94\n",
      "[I 2024-09-27 17:42:47,532] Trial 0 finished with value: -0.028354503756653337 and parameters: {'model__alpha': 0.13266376124474138}. Best is trial 0 with value: -0.028354503756653337.\n",
      "[I 2024-09-27 17:42:47,544] Trial 6 finished with value: -0.02834747705771754 and parameters: {'model__alpha': 1.1839405393006181e-06}. Best is trial 6 with value: -0.02834747705771754.\n",
      "[I 2024-09-27 17:42:47,573] Trial 1 finished with value: -0.02836523170117783 and parameters: {'model__alpha': 6.069479737329444e-06}. Best is trial 6 with value: -0.02834747705771754.\n",
      "[I 2024-09-27 17:42:47,673] Trial 11 finished with value: -0.028349580784749126 and parameters: {'model__alpha': 7.536801178309154e-05}. Best is trial 6 with value: -0.02834747705771754.\n",
      "[I 2024-09-27 17:42:47,688] Trial 7 finished with value: -0.028358125053521824 and parameters: {'model__alpha': 7.575307791570849e-06}. Best is trial 6 with value: -0.02834747705771754.\n",
      "[I 2024-09-27 17:42:47,694] Trial 5 finished with value: -0.028477408560289935 and parameters: {'model__alpha': 2.844349186203022e-08}. Best is trial 6 with value: -0.02834747705771754.\n",
      "[I 2024-09-27 17:42:47,732] Trial 2 finished with value: -0.028362757121001163 and parameters: {'model__alpha': 6.585487689237476e-06}. Best is trial 6 with value: -0.02834747705771754.\n",
      "[I 2024-09-27 17:42:47,741] Trial 13 finished with value: -0.028336455470902452 and parameters: {'model__alpha': 4.752541118789812e-05}. Best is trial 13 with value: -0.028336455470902452.\n",
      "[I 2024-09-27 17:42:47,840] Trial 9 finished with value: -0.028470238985416552 and parameters: {'model__alpha': 1.1770423661294783e-08}. Best is trial 13 with value: -0.028336455470902452.\n",
      "[I 2024-09-27 17:42:47,976] Trial 15 finished with value: -0.028477682576042586 and parameters: {'model__alpha': 0.03866228518667932}. Best is trial 13 with value: -0.028336455470902452.\n",
      "[I 2024-09-27 17:42:47,994] Trial 10 finished with value: -0.028353938174428665 and parameters: {'model__alpha': 0.0014139768857828066}. Best is trial 13 with value: -0.028336455470902452.\n",
      "[I 2024-09-27 17:42:48,038] Trial 3 finished with value: -0.028351680029193693 and parameters: {'model__alpha': 0.0010940279345101568}. Best is trial 13 with value: -0.028336455470902452.\n",
      "[I 2024-09-27 17:42:48,045] Trial 8 finished with value: -0.028360234239784708 and parameters: {'model__alpha': 0.005809877489093583}. Best is trial 13 with value: -0.028336455470902452.\n",
      "[I 2024-09-27 17:42:48,075] Trial 4 finished with value: -0.02847943371496299 and parameters: {'model__alpha': 6.99112523826651}. Best is trial 13 with value: -0.028336455470902452.\n",
      "[I 2024-09-27 17:42:48,135] Trial 14 finished with value: -0.028342689840062676 and parameters: {'model__alpha': 1.2533825879016518}. Best is trial 13 with value: -0.028336455470902452.\n",
      "[I 2024-09-27 17:42:48,188] Trial 12 finished with value: -0.02835773308995248 and parameters: {'model__alpha': 4.055912035096277e-08}. Best is trial 13 with value: -0.028336455470902452.\n",
      "[I 2024-09-27 17:42:53,497] Trial 16 finished with value: -0.028362778048995327 and parameters: {'model__alpha': 0.016610144063352626}. Best is trial 13 with value: -0.028336455470902452.\n",
      "[I 2024-09-27 17:42:53,617] Trial 18 finished with value: -0.028342487411725244 and parameters: {'model__alpha': 4.6542640061611794e-05}. Best is trial 13 with value: -0.028336455470902452.\n",
      "[I 2024-09-27 17:42:53,760] Trial 17 finished with value: -0.028348768862563194 and parameters: {'model__alpha': 3.6522203442534035e-07}. Best is trial 13 with value: -0.028336455470902452.\n",
      "[I 2024-09-27 17:42:53,822] Trial 24 finished with value: -0.028351273277884628 and parameters: {'model__alpha': 0.0006375981374666508}. Best is trial 13 with value: -0.028336455470902452.\n",
      "[I 2024-09-27 17:42:53,824] Trial 20 finished with value: -0.02834668018247917 and parameters: {'model__alpha': 1.5107395334132198e-08}. Best is trial 13 with value: -0.028336455470902452.\n",
      "[I 2024-09-27 17:42:53,937] Trial 22 finished with value: -0.02834217634344235 and parameters: {'model__alpha': 1.5325126352406856e-06}. Best is trial 13 with value: -0.028336455470902452.\n",
      "[I 2024-09-27 17:42:53,945] Trial 21 finished with value: -0.028345207080290993 and parameters: {'model__alpha': 8.211394702232092e-07}. Best is trial 13 with value: -0.028336455470902452.\n",
      "[I 2024-09-27 17:42:53,992] Trial 25 finished with value: -0.02834782107238175 and parameters: {'model__alpha': 3.6534996931829367e-07}. Best is trial 13 with value: -0.028336455470902452.\n",
      "[I 2024-09-27 17:42:54,012] Trial 19 finished with value: -0.028340686680842435 and parameters: {'model__alpha': 0.012287618701242087}. Best is trial 13 with value: -0.028336455470902452.\n",
      "[I 2024-09-27 17:42:54,031] Trial 23 finished with value: -0.028353979173786334 and parameters: {'model__alpha': 0.00040215695228859344}. Best is trial 13 with value: -0.028336455470902452.\n",
      "[I 2024-09-27 17:42:54,113] Trial 28 finished with value: -0.028352080475947603 and parameters: {'model__alpha': 4.950673491384734e-07}. Best is trial 13 with value: -0.028336455470902452.\n",
      "[I 2024-09-27 17:42:54,146] Trial 27 finished with value: -0.028354429865868606 and parameters: {'model__alpha': 5.15663656708151}. Best is trial 13 with value: -0.028336455470902452.\n",
      "[I 2024-09-27 17:42:54,157] Trial 26 finished with value: -0.028349324672950114 and parameters: {'model__alpha': 4.117448736451987e-07}. Best is trial 13 with value: -0.028336455470902452.\n",
      "[I 2024-09-27 17:42:54,242] Trial 31 finished with value: -0.028350759730031923 and parameters: {'model__alpha': 4.785776370230463}. Best is trial 13 with value: -0.028336455470902452.\n",
      "[I 2024-09-27 17:42:54,444] Trial 30 finished with value: -0.028350719018449592 and parameters: {'model__alpha': 3.615636956395594}. Best is trial 13 with value: -0.028336455470902452.\n",
      "[I 2024-09-27 17:42:54,605] Trial 29 finished with value: -0.028345855450427723 and parameters: {'model__alpha': 5.365526114139307e-07}. Best is trial 13 with value: -0.028336455470902452.\n",
      "[I 2024-09-27 17:42:59,835] Trial 32 finished with value: -0.028343998036950355 and parameters: {'model__alpha': 1.9334477003889594}. Best is trial 13 with value: -0.028336455470902452.\n",
      "[I 2024-09-27 17:42:59,982] Trial 33 finished with value: -0.0283564982440301 and parameters: {'model__alpha': 7.694025747071497e-05}. Best is trial 13 with value: -0.028336455470902452.\n",
      "[I 2024-09-27 17:43:00,225] Trial 38 finished with value: -0.02835079287129032 and parameters: {'model__alpha': 7.413719824412828e-05}. Best is trial 13 with value: -0.028336455470902452.\n",
      "[I 2024-09-27 17:43:00,274] Trial 41 finished with value: -0.02834942469634454 and parameters: {'model__alpha': 4.304197345769076e-05}. Best is trial 13 with value: -0.028336455470902452.\n",
      "[I 2024-09-27 17:43:00,281] Trial 35 finished with value: -0.02835817518921148 and parameters: {'model__alpha': 0.00010876826871138196}. Best is trial 13 with value: -0.028336455470902452.\n",
      "[I 2024-09-27 17:43:00,302] Trial 43 finished with value: -0.028354413892208264 and parameters: {'model__alpha': 0.25192950735508135}. Best is trial 13 with value: -0.028336455470902452.\n",
      "[I 2024-09-27 17:43:00,309] Trial 42 finished with value: -0.028348842440734635 and parameters: {'model__alpha': 0.00011690744460192727}. Best is trial 13 with value: -0.028336455470902452.\n",
      "[I 2024-09-27 17:43:00,312] Trial 34 finished with value: -0.028354361389701332 and parameters: {'model__alpha': 0.00024015453026609882}. Best is trial 13 with value: -0.028336455470902452.\n",
      "[I 2024-09-27 17:43:00,360] Trial 37 finished with value: -0.028476836633957232 and parameters: {'model__alpha': 9.927857381700827e-05}. Best is trial 13 with value: -0.028336455470902452.\n",
      "[I 2024-09-27 17:43:00,368] Trial 39 finished with value: -0.028344088306914816 and parameters: {'model__alpha': 8.892288191804092e-05}. Best is trial 13 with value: -0.028336455470902452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-27 17:43:00,399] Trial 36 finished with value: -0.0283498810490456 and parameters: {'model__alpha': 5.9426555808866965e-05}. Best is trial 13 with value: -0.028336455470902452.\n",
      "[I 2024-09-27 17:43:00,419] Trial 40 finished with value: -0.02847791378608188 and parameters: {'model__alpha': 0.00010321442612771965}. Best is trial 13 with value: -0.028336455470902452.\n",
      "[I 2024-09-27 17:43:00,423] Trial 44 finished with value: -0.028356527971139335 and parameters: {'model__alpha': 0.357398459945664}. Best is trial 13 with value: -0.028336455470902452.\n",
      "[I 2024-09-27 17:43:00,478] Trial 45 finished with value: -0.028352931186699067 and parameters: {'model__alpha': 7.746756383528239e-05}. Best is trial 13 with value: -0.028336455470902452.\n",
      "[I 2024-09-27 17:43:00,519] Trial 47 finished with value: -0.02847808584526007 and parameters: {'model__alpha': 0.00013226043446301858}. Best is trial 13 with value: -0.028336455470902452.\n",
      "[I 2024-09-27 17:43:00,525] Trial 46 finished with value: -0.028350964593944768 and parameters: {'model__alpha': 4.256287153258409e-05}. Best is trial 13 with value: -0.028336455470902452.\n",
      "[I 2024-09-27 17:43:01,063] Trial 48 finished with value: -0.028356820858097202 and parameters: {'model__alpha': 4.5317147221072925e-05}. Best is trial 13 with value: -0.028336455470902452.\n",
      "[I 2024-09-27 17:43:01,081] Trial 49 finished with value: -0.028357234251630007 and parameters: {'model__alpha': 5.408780479269408e-05}. Best is trial 13 with value: -0.028336455470902452.\n"
     ]
    }
   ],
   "source": [
    "model = Ridge(random_state=SEED)\n",
    "pipeline = create_pipeline(model)\n",
    "param_distr = {\n",
    "    \"model__alpha\": opt_distr.FloatDistribution(1e-8, 10, log=True),\n",
    "}\n",
    "optuna_search_ridge = hyperparam_tuning(\n",
    "    pipeline, \n",
    "    param_distr,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    **OPTUNA_SEARCH_CONFIG,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "59e0899d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best params are {'model__alpha': 4.752541118789812e-05}\n",
      "The best avg MSE from CV is 0.02834\n"
     ]
    }
   ],
   "source": [
    "print(f\"The best params are {optuna_search_ridge.best_params_}\")\n",
    "print(f\"The best avg MSE from CV is {-optuna_search_ridge.best_score_:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d5fcc984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"dev/ridge_optuna_CV.pkl\", \"wb\") as wf:\n",
    "#     pickle.dump(optuna_search_ridge, wf)\n",
    "\n",
    "# with open(\"dev/ridge_optuna_CV.pkl\", \"rb\") as rf:\n",
    "#     optuna_search_ridge = pickle.load(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "49311336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>r2_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>in-sample</th>\n",
       "      <td>0.020151</td>\n",
       "      <td>0.870918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out-of-sample</th>\n",
       "      <td>0.019178</td>\n",
       "      <td>0.885083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               mean_squared_error  r2_score\n",
       "in-sample                0.020151  0.870918\n",
       "out-of-sample            0.019178  0.885083"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_ridge_df = compute_metrics(\n",
    "    [mean_squared_error, r2_score],\n",
    "    optuna_search_ridge.best_estimator_,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    ")\n",
    "metrics_ridge_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1028abc",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5afca7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_3484\\2729002508.py:9: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.\n",
      "  optuna_search = OptunaSearchCV(\n",
      "[I 2024-09-27 17:43:01,216] A new study created in memory with name: no-name-f38c1297-d626-48a3-b1b6-f6414df3e097\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.5343590669709477, tolerance: 0.013162582551526084\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.519179891502397, tolerance: 0.013162582551526084\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.4921605593732075, tolerance: 0.013162582551526084\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.522141753350369, tolerance: 0.013162582551526084\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.5246965039315077, tolerance: 0.013162582551526084\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.2008559701045871, tolerance: 0.013162582551526084\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.5206775897036846, tolerance: 0.013162582551526084\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.300485256891625, tolerance: 0.013937601103862858\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.2921856793706916, tolerance: 0.013937601103862858\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.287865236377149, tolerance: 0.013937601103862858\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.2923368081530957, tolerance: 0.013937601103862858\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.29199437170969, tolerance: 0.013937601103862858\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.6657592088355755, tolerance: 0.013937601103862858\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.291782134317836, tolerance: 0.013937601103862858\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.2577968015268763, tolerance: 0.013937601103862858\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.6242566216568766, tolerance: 0.013872948527430694\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.6294783293967763, tolerance: 0.013872948527430694\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.6315162030587107, tolerance: 0.013872948527430694\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5872877545419231, tolerance: 0.013872948527430694\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.6324134367427647, tolerance: 0.013872948527430694\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.633303892631911, tolerance: 0.013872948527430694\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.6304095385696677, tolerance: 0.013872948527430694\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.318798436294447, tolerance: 0.013872948527430694\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "[I 2024-09-27 17:43:04,581] Trial 1 finished with value: -0.06011484750233134 and parameters: {'model__alpha': 9.5434616720936}. Best is trial 1 with value: -0.06011484750233134.\n",
      "[I 2024-09-27 17:43:04,779] Trial 8 finished with value: -0.044063074410275335 and parameters: {'model__alpha': 0.9627502078880407}. Best is trial 8 with value: -0.044063074410275335.\n",
      "[I 2024-09-27 17:43:04,931] Trial 6 finished with value: -0.05822337371679598 and parameters: {'model__alpha': 4.461560679864273}. Best is trial 8 with value: -0.044063074410275335.\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.6545435963056963, tolerance: 0.014255177010653748\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-27 17:43:05,139] Trial 12 finished with value: -0.0317548031797133 and parameters: {'model__alpha': 0.011011832204972097}. Best is trial 12 with value: -0.0317548031797133.\n",
      "[I 2024-09-27 17:43:05,285] Trial 5 finished with value: -0.024453970757543526 and parameters: {'model__alpha': 0.0006792378349012558}. Best is trial 5 with value: -0.024453970757543526.\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.708043322878503, tolerance: 0.014255177010653748\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.72145700175341, tolerance: 0.014255177010653748\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.7257636264069984, tolerance: 0.014255177010653748\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.291704916309695, tolerance: 0.014255177010653748\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.720098170897674, tolerance: 0.014255177010653748\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.26699959726797573, tolerance: 0.014255177010653748\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "[I 2024-09-27 17:43:05,505] Trial 10 finished with value: -0.025067958783365672 and parameters: {'model__alpha': 0.0003183677570584421}. Best is trial 5 with value: -0.024453970757543526.\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.5255646283771687, tolerance: 0.013162582551526084\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.7355145000931307, tolerance: 0.014255177010653748\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.5153461114972715, tolerance: 0.013162582551526084\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.3312283505251123, tolerance: 0.013911133328073113\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "[I 2024-09-27 17:43:06,082] Trial 3 finished with value: -0.041294934576966244 and parameters: {'model__alpha': 0.10908881492191515}. Best is trial 5 with value: -0.024453970757543526.\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.522520997823054, tolerance: 0.013162582551526084\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "[I 2024-09-27 17:43:06,091] Trial 9 finished with value: -0.041360751676587496 and parameters: {'model__alpha': 0.09850672950771303}. Best is trial 5 with value: -0.024453970757543526.\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.3702042180476783, tolerance: 0.013911133328073113\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.3378340395096857, tolerance: 0.013911133328073113\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.339330018120977, tolerance: 0.013911133328073113\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.340069901512353, tolerance: 0.013911133328073113\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.3385995771275225, tolerance: 0.013911133328073113\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.2923627144898475, tolerance: 0.013937601103862858\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.3531142274494057, tolerance: 0.013911133328073113\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.3174695111466104, tolerance: 0.013911133328073113\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.0758728425221027, tolerance: 0.014154700321222362\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.2653973132270218, tolerance: 0.013937601103862858\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.2922525109901937, tolerance: 0.013937601103862858\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.0599355310306384, tolerance: 0.014154700321222362\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.0623397920026934, tolerance: 0.014154700321222362\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.074084546095591, tolerance: 0.014154700321222362\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.073656022093003, tolerance: 0.014154700321222362\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.06103446350296, tolerance: 0.014154700321222362\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.391309803994872, tolerance: 0.013872948527430694\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.4314681202778834, tolerance: 0.013976191782343462\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.6291492928657454, tolerance: 0.013872948527430694\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.063308943100181, tolerance: 0.014154700321222362\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.630182875851955, tolerance: 0.013872948527430694\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-27 17:43:08,277] Trial 21 finished with value: -0.04658986162721246 and parameters: {'model__alpha': 1.3325840541932876}. Best is trial 5 with value: -0.024453970757543526.\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.7762829223953092, tolerance: 0.013976191782343462\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "[I 2024-09-27 17:43:08,614] Trial 19 finished with value: -0.0358827849236424 and parameters: {'model__alpha': 0.04086252520600139}. Best is trial 5 with value: -0.024453970757543526.\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.310960562773037, tolerance: 0.013976191782343462\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.032560319512247, tolerance: 0.014402571243910837\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.415129242009115, tolerance: 0.013976191782343462\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.362807993932162, tolerance: 0.013976191782343462\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.728205435484728, tolerance: 0.014255177010653748\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.3166825490418193, tolerance: 0.014255177010653748\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.4166275637868364, tolerance: 0.013976191782343462\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.4169799333544817, tolerance: 0.013976191782343462\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.4159693853739537, tolerance: 0.013976191782343462\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.72180189021247, tolerance: 0.014255177010653748\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "[I 2024-09-27 17:43:08,830] Trial 2 finished with value: -0.029369334403382213 and parameters: {'model__alpha': 1.6167004301521917e-06}. Best is trial 5 with value: -0.024453970757543526.\n",
      "[I 2024-09-27 17:43:08,835] Trial 18 finished with value: -0.04118345063712936 and parameters: {'model__alpha': 0.12738722916926878}. Best is trial 5 with value: -0.024453970757543526.\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.150449609918367, tolerance: 0.014402571243910837\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "[I 2024-09-27 17:43:09,243] Trial 14 finished with value: -0.02889477479907865 and parameters: {'model__alpha': 1.7264054285009586e-05}. Best is trial 5 with value: -0.024453970757543526.\n",
      "[I 2024-09-27 17:43:09,521] Trial 22 finished with value: -0.02455468634683989 and parameters: {'model__alpha': 0.0008724242529231509}. Best is trial 5 with value: -0.024453970757543526.\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.5248310064124326, tolerance: 0.013162582551526084\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.9717320683325257, tolerance: 0.014402571243910837\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.024087650363932, tolerance: 0.014402571243910837\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.023101781506825, tolerance: 0.014402571243910837\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "[I 2024-09-27 17:43:09,847] Trial 15 finished with value: -0.029209715470742307 and parameters: {'model__alpha': 6.293439667720306e-06}. Best is trial 5 with value: -0.024453970757543526.\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.0252234963512414, tolerance: 0.014402571243910837\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "[I 2024-09-27 17:43:09,900] Trial 13 finished with value: -0.02947882764739273 and parameters: {'model__alpha': 3.3515789250318804e-07}. Best is trial 5 with value: -0.024453970757543526.\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.4247991774680577, tolerance: 0.013911133328073113\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.3375505581750087, tolerance: 0.013911133328073113\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.3383590339559293, tolerance: 0.013911133328073113\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.025416770746446, tolerance: 0.014402571243910837\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.024447013546648, tolerance: 0.014402571243910837\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "[I 2024-09-27 17:43:09,931] Trial 0 finished with value: -0.029384758325073552 and parameters: {'model__alpha': 1.188787842410988e-06}. Best is trial 5 with value: -0.024453970757543526.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-27 17:43:10,041] Trial 7 finished with value: -0.029554483979325676 and parameters: {'model__alpha': 1.4020829420062377e-07}. Best is trial 5 with value: -0.024453970757543526.\n",
      "[I 2024-09-27 17:43:10,043] Trial 4 finished with value: -0.029491805421402662 and parameters: {'model__alpha': 2.508645748209536e-07}. Best is trial 5 with value: -0.024453970757543526.\n",
      "[I 2024-09-27 17:43:10,090] Trial 11 finished with value: -0.029763421794695887 and parameters: {'model__alpha': 4.595103855827847e-08}. Best is trial 5 with value: -0.024453970757543526.\n",
      "[I 2024-09-27 17:43:10,396] Trial 23 finished with value: -0.026063179837312628 and parameters: {'model__alpha': 0.00016429995412086025}. Best is trial 5 with value: -0.024453970757543526.\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.2923393753979093, tolerance: 0.013937601103862858\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.0607113003619606, tolerance: 0.014154700321222362\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.52427763478587, tolerance: 0.013162582551526084\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.0595360434587615, tolerance: 0.014154700321222362\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.0784516893917697, tolerance: 0.014154700321222362\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.5255304287518388, tolerance: 0.013162582551526084\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.6294341979252485, tolerance: 0.013872948527430694\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "[I 2024-09-27 17:43:11,501] Trial 24 finished with value: -0.03332766875045887 and parameters: {'model__alpha': 0.02608559485554247}. Best is trial 5 with value: -0.024453970757543526.\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.4168453079880687, tolerance: 0.013976191782343462\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.292361902853798, tolerance: 0.013937601103862858\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.3222590381275277, tolerance: 0.013976191782343462\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.2923242138129525, tolerance: 0.013937601103862858\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.4162518745572146, tolerance: 0.013976191782343462\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.726369747643322, tolerance: 0.014255177010653748\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.629163291285, tolerance: 0.013872948527430694\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.0253318495212955, tolerance: 0.014402571243910837\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.97024763246307, tolerance: 0.014402571243910837\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.027626487381112064, tolerance: 0.014154700321222362\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.0250075558938785, tolerance: 0.014402571243910837\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "[I 2024-09-27 17:43:13,116] Trial 16 finished with value: -0.029848337589208164 and parameters: {'model__alpha': 1.2475922932088677e-08}. Best is trial 5 with value: -0.024453970757543526.\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.6295967075456974, tolerance: 0.013872948527430694\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "[I 2024-09-27 17:43:13,164] Trial 17 finished with value: -0.029215797830049295 and parameters: {'model__alpha': 6.085205558658379e-06}. Best is trial 5 with value: -0.024453970757543526.\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.3377975011673016, tolerance: 0.013911133328073113\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "[I 2024-09-27 17:43:13,225] Trial 20 finished with value: -0.029605964334113482 and parameters: {'model__alpha': 1.1220533645409833e-07}. Best is trial 5 with value: -0.024453970757543526.\n",
      "[I 2024-09-27 17:43:13,758] Trial 28 finished with value: -0.025623337135081452 and parameters: {'model__alpha': 0.00020855844761641368}. Best is trial 5 with value: -0.024453970757543526.\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.7281146711748923, tolerance: 0.014255177010653748\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "[I 2024-09-27 17:43:13,894] Trial 29 finished with value: -0.024535911774859843 and parameters: {'model__alpha': 0.0005656842528034156}. Best is trial 5 with value: -0.024453970757543526.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.0598839701526064, tolerance: 0.014154700321222362\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "[I 2024-09-27 17:43:14,042] Trial 26 finished with value: -0.027353880871364474 and parameters: {'model__alpha': 7.146622700558058e-05}. Best is trial 5 with value: -0.024453970757543526.\n",
      "[I 2024-09-27 17:43:14,070] Trial 34 finished with value: -0.024445839139380567 and parameters: {'model__alpha': 0.0007140851590500408}. Best is trial 34 with value: -0.024445839139380567.\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.725063491894924, tolerance: 0.014255177010653748\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "[I 2024-09-27 17:43:14,206] Trial 31 finished with value: -0.024927962583369264 and parameters: {'model__alpha': 0.0003657394816974482}. Best is trial 34 with value: -0.024445839139380567.\n",
      "[I 2024-09-27 17:43:14,458] Trial 27 finished with value: -0.027181968359540114 and parameters: {'model__alpha': 8.642183461454682e-05}. Best is trial 34 with value: -0.024445839139380567.\n",
      "[I 2024-09-27 17:43:14,645] Trial 36 finished with value: -0.02587341662283673 and parameters: {'model__alpha': 0.0014319663432536493}. Best is trial 34 with value: -0.024445839139380567.\n",
      "[I 2024-09-27 17:43:14,698] Trial 33 finished with value: -0.024675915563244305 and parameters: {'model__alpha': 0.0004556673564741601}. Best is trial 34 with value: -0.024445839139380567.\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.3375624718858363, tolerance: 0.013911133328073113\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "[I 2024-09-27 17:43:14,837] Trial 35 finished with value: -0.024483386979927187 and parameters: {'model__alpha': 0.0006219461715250697}. Best is trial 34 with value: -0.024445839139380567.\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.4166615749582316, tolerance: 0.013976191782343462\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.3379323195442656, tolerance: 0.013911133328073113\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.059553217085265, tolerance: 0.014154700321222362\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "[I 2024-09-27 17:43:15,925] Trial 37 finished with value: -0.02598844598510428 and parameters: {'model__alpha': 0.001511864546669486}. Best is trial 34 with value: -0.024445839139380567.\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.0252381887169753, tolerance: 0.014402571243910837\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.060096501589494, tolerance: 0.014154700321222362\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "[I 2024-09-27 17:43:16,128] Trial 25 finished with value: -0.0297752983115143 and parameters: {'model__alpha': 4.1599369426804254e-08}. Best is trial 34 with value: -0.024445839139380567.\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.41683800239313, tolerance: 0.013976191782343462\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.4165850265190865, tolerance: 0.013976191782343462\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "[I 2024-09-27 17:43:17,261] Trial 38 finished with value: -0.026369116300885603 and parameters: {'model__alpha': 0.0018262877875155053}. Best is trial 34 with value: -0.024445839139380567.\n",
      "[I 2024-09-27 17:43:17,493] Trial 40 finished with value: -0.02604980768522948 and parameters: {'model__alpha': 0.0015611462999287166}. Best is trial 34 with value: -0.024445839139380567.\n",
      "[I 2024-09-27 17:43:17,521] Trial 39 finished with value: -0.024487264950304156 and parameters: {'model__alpha': 0.0006174927386443066}. Best is trial 34 with value: -0.024445839139380567.\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.025327228026795, tolerance: 0.014402571243910837\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "[I 2024-09-27 17:43:17,654] Trial 32 finished with value: -0.029847582239386997 and parameters: {'model__alpha': 1.3906903471861768e-08}. Best is trial 34 with value: -0.024445839139380567.\n",
      "[I 2024-09-27 17:43:17,688] Trial 42 finished with value: -0.02904895039198251 and parameters: {'model__alpha': 0.003801763940888984}. Best is trial 34 with value: -0.024445839139380567.\n",
      "[I 2024-09-27 17:43:17,872] Trial 41 finished with value: -0.02838818556126825 and parameters: {'model__alpha': 0.0030589455381761347}. Best is trial 34 with value: -0.024445839139380567.\n",
      "D:\\python\\venvs\\DeepLearning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.0251755039815644, tolerance: 0.014402571243910837\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "[I 2024-09-27 17:43:17,928] Trial 30 finished with value: -0.0297270226593949 and parameters: {'model__alpha': 5.967725114699814e-08}. Best is trial 34 with value: -0.024445839139380567.\n",
      "[I 2024-09-27 17:43:17,998] Trial 44 finished with value: -0.027367214481989803 and parameters: {'model__alpha': 0.002363767618803363}. Best is trial 34 with value: -0.024445839139380567.\n",
      "[I 2024-09-27 17:43:18,021] Trial 43 finished with value: -0.02711207451078107 and parameters: {'model__alpha': 0.002213515259762774}. Best is trial 34 with value: -0.024445839139380567.\n",
      "[I 2024-09-27 17:43:18,035] Trial 46 finished with value: -0.026024147680651814 and parameters: {'model__alpha': 0.0015386184216324562}. Best is trial 34 with value: -0.024445839139380567.\n",
      "[I 2024-09-27 17:43:18,042] Trial 45 finished with value: -0.027347908345096473 and parameters: {'model__alpha': 0.0023519763433806217}. Best is trial 34 with value: -0.024445839139380567.\n",
      "[I 2024-09-27 17:43:18,145] Trial 47 finished with value: -0.02856659256408252 and parameters: {'model__alpha': 0.0032475861048341936}. Best is trial 34 with value: -0.024445839139380567.\n",
      "[I 2024-09-27 17:43:18,147] Trial 49 finished with value: -0.02802879439120897 and parameters: {'model__alpha': 0.002770767903324589}. Best is trial 34 with value: -0.024445839139380567.\n",
      "[I 2024-09-27 17:43:18,157] Trial 48 finished with value: -0.026349154435671453 and parameters: {'model__alpha': 0.0018169940386826774}. Best is trial 34 with value: -0.024445839139380567.\n"
     ]
    }
   ],
   "source": [
    "model = Lasso(random_state=SEED)\n",
    "pipeline = create_pipeline(model)\n",
    "param_distr = {\n",
    "    \"model__alpha\": opt_distr.FloatDistribution(1e-8, 10, log=True),\n",
    "}\n",
    "optuna_search_lasso = hyperparam_tuning(\n",
    "    pipeline, \n",
    "    param_distr,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    **OPTUNA_SEARCH_CONFIG,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "76b1990c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best params are {'model__alpha': 0.0007140851590500408}\n",
      "The best avg MSE from CV is 0.02445\n"
     ]
    }
   ],
   "source": [
    "print(f\"The best params are {optuna_search_lasso.best_params_}\")\n",
    "print(f\"The best avg MSE from CV is {-optuna_search_lasso.best_score_:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e390e849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"dev/lasso_optuna_CV.pkl\", \"wb\") as wf:\n",
    "#     pickle.dump(optuna_search_lasso, wf)\n",
    "\n",
    "# with open(\"dev/lasso_optuna_CV.pkl\", \"rb\") as rf:\n",
    "#     optuna_search_lasso = pickle.load(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "17c5f595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>r2_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>in-sample</th>\n",
       "      <td>0.011957</td>\n",
       "      <td>0.923405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out-of-sample</th>\n",
       "      <td>0.014819</td>\n",
       "      <td>0.911204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               mean_squared_error  r2_score\n",
       "in-sample                0.011957  0.923405\n",
       "out-of-sample            0.014819  0.911204"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_lasso_df = compute_metrics(\n",
    "    [mean_squared_error, r2_score],\n",
    "    optuna_search_lasso.best_estimator_,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    ")\n",
    "metrics_lasso_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc54a514",
   "metadata": {},
   "source": [
    "Now we compare all models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "16574ece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">LR_numerical</th>\n",
       "      <th colspan=\"2\" halign=\"left\">LR</th>\n",
       "      <th colspan=\"2\" halign=\"left\">truncated_pinv</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Ridge</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Lasso</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>r2_score</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>r2_score</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>r2_score</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>r2_score</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>r2_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>in-sample</th>\n",
       "      <td>0.021603</td>\n",
       "      <td>0.861617</td>\n",
       "      <td>0.011887</td>\n",
       "      <td>0.923856</td>\n",
       "      <td>0.015699</td>\n",
       "      <td>0.899435</td>\n",
       "      <td>0.020151</td>\n",
       "      <td>0.870918</td>\n",
       "      <td>0.011957</td>\n",
       "      <td>0.923405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out-of-sample</th>\n",
       "      <td>0.020817</td>\n",
       "      <td>0.875258</td>\n",
       "      <td>0.017565</td>\n",
       "      <td>0.894748</td>\n",
       "      <td>0.019424</td>\n",
       "      <td>0.883607</td>\n",
       "      <td>0.019178</td>\n",
       "      <td>0.885083</td>\n",
       "      <td>0.014819</td>\n",
       "      <td>0.911204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    LR_numerical                           LR            \\\n",
       "              mean_squared_error  r2_score mean_squared_error  r2_score   \n",
       "in-sample               0.021603  0.861617           0.011887  0.923856   \n",
       "out-of-sample           0.020817  0.875258           0.017565  0.894748   \n",
       "\n",
       "                  truncated_pinv                        Ridge            \\\n",
       "              mean_squared_error  r2_score mean_squared_error  r2_score   \n",
       "in-sample               0.015699  0.899435           0.020151  0.870918   \n",
       "out-of-sample           0.019424  0.883607           0.019178  0.885083   \n",
       "\n",
       "                           Lasso            \n",
       "              mean_squared_error  r2_score  \n",
       "in-sample               0.011957  0.923405  \n",
       "out-of-sample           0.014819  0.911204  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_all_dict = {\n",
    "    \"LR_numerical\": metrics_df,\n",
    "    \"LR\": metrics_lr_df,\n",
    "    \"truncated_pinv\": metrics_truncated_pinv_df,\n",
    "    \"Ridge\": metrics_ridge_df,\n",
    "    \"Lasso\": metrics_lasso_df,\n",
    "}\n",
    "all_metrics = []\n",
    "for model_name, metric_iter in metrics_all_dict.items():\n",
    "    metric_local = metric_iter.copy()\n",
    "    metric_local.columns = pd.MultiIndex.from_tuples([(model_name, col) for col in metric_local.columns])\n",
    "    all_metrics.append(metric_local)\n",
    "all_metrics_df = pd.concat(all_metrics, axis=1)\n",
    "all_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5279627",
   "metadata": {},
   "source": [
    "<span style=\"color: blue;\"><strong>Conclusion:</strong></span>\n",
    "\n",
    "The best model is Lasso, since it achieves the lowest MSE and highest $R^2$ on both training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ae7a2419",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.c) For the  Lasso regularization technique, how many coefficients are non-zero? \n",
    "\n",
    "#Compare this number with the number of coefficients retained by the Ridge and truncated pseudoinverse techniques and provide an explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "199398ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of non-zeros with threshold 1e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "truncated_pinv     97\n",
       "ridge             294\n",
       "lasso             102\n",
       "dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with open(\"dev/truncated_pinv_optuna_CV.pkl\", \"rb\") as rf:\n",
    "#     optuna_search_truncated_pinv = pickle.load(rf)\n",
    "\n",
    "# with open(\"dev/ridge_optuna_CV.pkl\", \"rb\") as rf:\n",
    "#     optuna_search_ridge = pickle.load(rf)\n",
    "\n",
    "# with open(\"dev/lasso_optuna_CV.pkl\", \"rb\") as rf:\n",
    "#     optuna_search_lasso = pickle.load(rf)\n",
    "\n",
    "coeffs_ridge = optuna_search_ridge.best_estimator_[\"model\"].coef_\n",
    "coeffs_lasso = optuna_search_lasso.best_estimator_[\"model\"].coef_\n",
    "# For convenience of counting nonzeros, we pad the coeffs from truncated pinv with zeros\n",
    "coeffs_truncated_pinv = np.zeros(coeffs_ridge.shape)  # (K_full,)\n",
    "coeffs_truncated_pinv_model = optuna_search_truncated_pinv.best_estimator_[\"model\"][\"estimator\"].coef_  # (K,), where K_full < K \n",
    "coeffs_truncated_pinv[:coeffs_truncated_pinv_model.shape[0]] = coeffs_truncated_pinv_model\n",
    "coeffs_df = pd.DataFrame(\n",
    "    {\n",
    "        \"truncated_pinv\": coeffs_truncated_pinv,\n",
    "        \"ridge\": coeffs_ridge,\n",
    "        \"lasso\": coeffs_lasso,\n",
    "    }\n",
    ")\n",
    "eps = 1e-6\n",
    "num_non_zeros_df = (np.abs(coeffs_df) > eps).sum()\n",
    "print(f\"Number of non-zeros with threshold {eps}\")\n",
    "num_non_zeros_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870c8f75",
   "metadata": {},
   "source": [
    "<span style=\"color: blue;\"><strong>Discussion:</strong></span>\n",
    "1. Lasso has fewer non-zero coefficients than Ridge. The reason is that Lasso tends to shrink coefficients towards 0.\n",
    "1. Truncated pseudo-inverse has a pre-set number of nonzeros, and in our case, it's smaller than number of non-zeros of Lasso.\n",
    "1. From the comparison of MSE and $R^2$, Lasso achieves the best tradeoff between bias (too few non-zero coefficients) and variance (too many non-zero coefficients). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e12435fe-6e93-477f-ac34-3440e08463f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.d) Based on your findings from Questions 2 and 3, which model would you recommend? Justify your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebb5913",
   "metadata": {},
   "source": [
    "<span style=\"color: blue;\"><strong>Recommendation: Lasso</strong></span>\n",
    "1. From the perspective of metrics on the training and test set, Lasso outperforms all other models.\n",
    "1. From the analysis on the number of non-zero coefficients, Lasso has the best tradeoff between bias and variance. It also automatically performs feature selection, leading to better interpretability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb98c73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
